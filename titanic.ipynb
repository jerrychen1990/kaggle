{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Age     SibSp     Parch      Fare\n",
       "Survived  1.000000 -0.338481 -0.077221 -0.035322  0.081629  0.257307\n",
       "Pclass   -0.338481  1.000000 -0.369226  0.083081  0.018443 -0.549500\n",
       "Age      -0.077221 -0.369226  1.000000 -0.308247 -0.189119  0.096067\n",
       "SibSp    -0.035322  0.083081 -0.308247  1.000000  0.414838  0.159651\n",
       "Parch     0.081629  0.018443 -0.189119  0.414838  1.000000  0.216225\n",
       "Fare      0.257307 -0.549500  0.096067  0.159651  0.216225  1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117667518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117667518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11771bb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11777ac18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x117705780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119d206a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()\n",
    "train_data.head()\n",
    "train_data.info()\n",
    "test_data.info()\n",
    "\n",
    "train_corr = train_data.drop('PassengerId', axis=1).corr()\n",
    "train_corr\n",
    "a = plt.subplots(figsize = (15,9))\n",
    "sns.heatmap(train_corr,vmin=-1, vmax=1,annot=True, square=True)\n",
    "\n",
    "\n",
    "train_data.groupby(\"Pclass\")['Survived'].mean().plot.bar()\n",
    "\n",
    "train_data.groupby(['Sex'])['Sex','Survived'].mean().plot.bar()\n",
    "\n",
    "g = sns.FacetGrid(train_data, col='Survived',size=5)\n",
    "g.map(plt.hist, 'Age', bins=40)\n",
    "\n",
    "g = sns.FacetGrid(train_data, col='Survived',size=5)\n",
    "g.map(plt.hist, 'Fare', bins=40)\n",
    "sns.countplot(\"Embarked\", hue = 'Survived', data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_parse(df):\n",
    "    df['SibSp_Parch'] = df['SibSp'] + df['Parch']\n",
    "    df.Embarked.fillna(df.Embarked.mode()[0], inplace=True)\n",
    "\n",
    "    df[\"Fare\"].fillna(14.435422,inplace=True)\n",
    "\n",
    "    df['Name1'] = df['Name'].str.extract('.+,(.+)', expand=False).str.extract('^(.+?)\\.', expand=False).str.strip()\n",
    "\n",
    "    df['Name1'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer' , inplace = True)\n",
    "    df['Name1'].replace(['Jonkheer', 'Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty' , inplace = True)\n",
    "    df['Name1'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs', inplace = True)\n",
    "    df['Name1'].replace(['Mlle', 'Miss'], 'Miss', inplace = True)\n",
    "    df['Name1'].replace(['Mr'], 'Mr' , inplace = True)\n",
    "    df['Name1'].replace(['Master'], 'Master' , inplace = True)\n",
    "    df = pd.get_dummies(df,columns=['Pclass','Sex','SibSp','Parch','SibSp_Parch', \"Embarked\", 'Name1'])\n",
    "\n",
    "    df['Name2'] = df['Name'].apply(lambda x: x.split('.')[1])\n",
    "    Name2_sum = df['Name2'].value_counts().reset_index()\n",
    "    Name2_sum.columns=['Name2','Name2_sum']\n",
    "    df = pd.merge(df,Name2_sum,how='left',on='Name2')\n",
    "\n",
    "    #由于出现一次时该特征时无效特征,用one来代替出现一次的姓\n",
    "    df.loc[df['Name2_sum'] == 1 , 'Name2_new'] = 'one'\n",
    "    df.loc[df['Name2_sum'] > 1 , 'Name2_new'] = df['Name2']\n",
    "    del df['Name2']\n",
    "    df = pd.get_dummies(df,columns=['Name2_new'])\n",
    "    del df['Name']\n",
    "\n",
    "\n",
    "\n",
    "    df['Ticket_Letter'] = df['Ticket'].str.split().str[0]\n",
    "    df['Ticket_Letter'] = df['Ticket_Letter'].apply(lambda x:np.nan if x.isnumeric() else x)\n",
    "    df.drop('Ticket',inplace=True,axis=1)\n",
    "    df = pd.get_dummies(df,columns=['Ticket_Letter'],drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df.loc[df[\"Age\"].isnull() ,\"age_nan\"] = 1\n",
    "    df.loc[df[\"Age\"].notnull() ,\"age_nan\"] = 0\n",
    "    df = pd.get_dummies(df,columns=['age_nan'])\n",
    "\n",
    "    missing_age = df.drop(['Survived','Cabin'],axis=1)\n",
    "\n",
    "    #分列处理\n",
    "\n",
    "\n",
    "    #将Age完整的项作为训练集、将Age缺失的项作为测试集。\n",
    "    missing_age_train = missing_age[missing_age['Age'].notnull()]\n",
    "    missing_age_test = missing_age[missing_age['Age'].isnull()]\n",
    "    missing_age_X_train = missing_age_train.drop(['Age'], axis=1)\n",
    "    missing_age_Y_train = missing_age_train['Age']\n",
    "    missing_age_X_test = missing_age_test.drop(['Age'], axis=1)\n",
    "\n",
    "    # 先将数据标准化\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    #用测试集训练并标准化\n",
    "\n",
    "\n",
    "    ss.fit(missing_age_X_train)\n",
    "    missing_age_X_train = ss.transform(missing_age_X_train)\n",
    "    missing_age_X_test = ss.transform(missing_age_X_test)\n",
    "    lin = linear_model.BayesianRidge()\n",
    "    lin.fit(missing_age_X_train,missing_age_Y_train)\n",
    "    df.loc[(df['Age'].isnull()), 'Age'] = lin.predict(missing_age_X_test)\n",
    "\n",
    "    df['Age'] = pd.cut(df['Age'], bins=[0,10,18,30,50,100],labels=[1,2,3,4,5])\n",
    "    df = pd.get_dummies(df,columns=['Age'])\n",
    "\n",
    "\n",
    "    df['Cabin_nan'] = df['Cabin'].apply(lambda x:str(x)[0] if pd.notnull(x) else x)\n",
    "    df = pd.get_dummies(df,columns=['Cabin_nan'])\n",
    "    df.loc[df[\"Cabin\"].isnull() ,\"Cabin_nan\"] = 1\n",
    "    df.loc[df[\"Cabin\"].notnull() ,\"Cabin_nan\"] = 0\n",
    "    df = pd.get_dummies(df,columns=['Cabin_nan'])\n",
    "    df.drop(['Cabin', 'PassengerId'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 132.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:62: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:63: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_nan_A</th>\n",
       "      <th>Cabin_nan_B</th>\n",
       "      <th>Cabin_nan_C</th>\n",
       "      <th>Cabin_nan_D</th>\n",
       "      <th>Cabin_nan_E</th>\n",
       "      <th>Cabin_nan_F</th>\n",
       "      <th>Cabin_nan_G</th>\n",
       "      <th>Cabin_nan_T</th>\n",
       "      <th>Cabin_nan_0.0</th>\n",
       "      <th>Cabin_nan_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  SibSp_0  \\\n",
       "0   7.2500         0         0         1           0         1        0   \n",
       "1  71.2833         1         0         0           1         0        0   \n",
       "2   7.9250         0         0         1           1         0        1   \n",
       "3  53.1000         1         0         0           1         0        0   \n",
       "4   8.0500         0         0         1           0         1        1   \n",
       "\n",
       "   SibSp_1  SibSp_2  SibSp_3      ...        Cabin_nan_A  Cabin_nan_B  \\\n",
       "0        1        0        0      ...                  0            0   \n",
       "1        1        0        0      ...                  0            0   \n",
       "2        0        0        0      ...                  0            0   \n",
       "3        1        0        0      ...                  0            0   \n",
       "4        0        0        0      ...                  0            0   \n",
       "\n",
       "   Cabin_nan_C  Cabin_nan_D  Cabin_nan_E  Cabin_nan_F  Cabin_nan_G  \\\n",
       "0            0            0            0            0            0   \n",
       "1            1            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            1            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Cabin_nan_T  Cabin_nan_0.0  Cabin_nan_1.0  \n",
       "0            0              0              1  \n",
       "1            0              1              0  \n",
       "2            0              0              1  \n",
       "3            0              1              0  \n",
       "4            0              0              1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Columns: 195 entries, Fare to Cabin_nan_1.0\n",
      "dtypes: float64(1), int64(1), uint8(193)\n",
      "memory usage: 188.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:22: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.50244517, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       [ 0.78684529,  1.76776695, -0.51015154, ..., -0.03352008,\n",
       "         1.835115  , -1.835115  ],\n",
       "       [-0.48885426, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       ...,\n",
       "       [-0.17626324, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       [-0.04438104,  1.76776695, -0.51015154, ..., -0.03352008,\n",
       "         1.835115  , -1.835115  ],\n",
       "       [-0.49237783, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(df, train_num):\n",
    "    train_data = df[:train_num]\n",
    "    test_data = df[train_num:]\n",
    "    train_data_X = train_data.drop(['Survived'],axis=1)\n",
    "    train_data_Y = train_data['Survived']\n",
    "    test_data_X = test_data.drop(['Survived'],axis=1)\n",
    "    return train_data_X, train_data_Y, test_data_X\n",
    "\n",
    "test_data['Survived'] = 0\n",
    "train_test = train_data.append(test_data)\n",
    "train_test.info()\n",
    "parsed_data = feature_parse(train_test)\n",
    "\n",
    "\n",
    "train_data_X, train_data_Y, test_data_X = split_data(parsed_data, train_data.shape[0])\n",
    "train_data_X.head()\n",
    "train_data_X.info()\n",
    "\n",
    "ss2 = StandardScaler()\n",
    "ss2.fit(train_data_X)\n",
    "train_data_X_sd = ss2.transform(train_data_X)\n",
    "test_data_X_sd = ss2.transform(test_data_X)\n",
    "train_data_X_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_nan_A</th>\n",
       "      <th>Cabin_nan_B</th>\n",
       "      <th>Cabin_nan_C</th>\n",
       "      <th>Cabin_nan_D</th>\n",
       "      <th>Cabin_nan_E</th>\n",
       "      <th>Cabin_nan_F</th>\n",
       "      <th>Cabin_nan_G</th>\n",
       "      <th>Cabin_nan_T</th>\n",
       "      <th>Cabin_nan_0.0</th>\n",
       "      <th>Cabin_nan_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  SibSp_0  \\\n",
       "0   7.2500         0         0         1           0         1        0   \n",
       "1  71.2833         1         0         0           1         0        0   \n",
       "2   7.9250         0         0         1           1         0        1   \n",
       "3  53.1000         1         0         0           1         0        0   \n",
       "4   8.0500         0         0         1           0         1        1   \n",
       "\n",
       "   SibSp_1  SibSp_2  SibSp_3      ...        Cabin_nan_A  Cabin_nan_B  \\\n",
       "0        1        0        0      ...                  0            0   \n",
       "1        1        0        0      ...                  0            0   \n",
       "2        0        0        0      ...                  0            0   \n",
       "3        1        0        0      ...                  0            0   \n",
       "4        0        0        0      ...                  0            0   \n",
       "\n",
       "   Cabin_nan_C  Cabin_nan_D  Cabin_nan_E  Cabin_nan_F  Cabin_nan_G  \\\n",
       "0            0            0            0            0            0   \n",
       "1            1            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            1            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Cabin_nan_T  Cabin_nan_0.0  Cabin_nan_1.0  \n",
       "0            0              0              1  \n",
       "1            0              1              0  \n",
       "2            0              0              1  \n",
       "3            0              1              0  \n",
       "4            0              0              1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Columns: 195 entries, Fare to Cabin_nan_1.0\n",
      "dtypes: float64(1), int64(1), uint8(193)\n",
      "memory usage: 188.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_data_X.head()\n",
    "train_data_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_result(model, x, y):\n",
    "    pred = model.predict(x)\n",
    "    acc = accuracy_score(pred, y)\n",
    "    auc = roc_auc_score(pred, y)\n",
    "    \n",
    "    return dict(acc=acc,auc=auc)\n",
    "\n",
    "eval_result(best_model, train_data_X_sd, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_train(clazz, best_params, grid_params, n_fold=5, scoring= 'roc_auc'):\n",
    "    best_params = dict(n_estimators = 115, max_depth = 15, learning_rate=0.05,\n",
    "                   subsample= 0.1, reg_alpha=0.05, reg_lambda=0.0, num_leaves=48)\n",
    "    model = clazz(**best_params)\n",
    "    clf = GridSearchCV(model, grid_params, cv=n_fold, n_jobs=1, verbose=1, scoring=scoring)\n",
    "    clf.fit(train_data_X_sd, train_data_Y)\n",
    "    detail = clf.cv_results_\n",
    "    best_params.update(clf.best_params_)\n",
    "    best_model = clazz(**best_params)\n",
    "    return detail, best_params, best_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 125 candidates, totalling 625 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 625 out of 625 | elapsed: 10.3min finished\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.18048449, 0.14693427, 0.14192662, 0.15140514, 0.16030822,\n",
       "         0.19293785, 0.1913074 , 0.22345662, 0.25505118, 0.21579518,\n",
       "         0.23977504, 0.22718439, 0.22665749, 0.24056678, 0.29609962,\n",
       "         0.36091838, 0.37112679, 0.34546738, 0.36721506, 0.33169899,\n",
       "         0.41961823, 0.44675999, 0.45850124, 0.45239191, 0.46020679,\n",
       "         0.25366445, 0.23899188, 0.23527775, 0.24234452, 0.24955258,\n",
       "         0.3628376 , 0.35122385, 0.34037585, 0.37172174, 0.39317956,\n",
       "         0.395086  , 0.40511475, 0.45792074, 0.4497056 , 0.4398284 ,\n",
       "         0.67002144, 0.67839317, 0.68353372, 0.59023185, 0.56567154,\n",
       "         0.77704201, 0.75448503, 0.7577548 , 0.8584466 , 0.78418365,\n",
       "         0.22914047, 0.23799672, 0.22862005, 0.22126923, 0.22194157,\n",
       "         0.32851152, 0.35017743, 0.36000419, 0.33453588, 0.32858839,\n",
       "         0.43997941, 0.47943783, 0.44619222, 0.46690359, 0.43763986,\n",
       "         0.64204993, 0.70734868, 0.70109739, 0.71646714, 0.71245837,\n",
       "         0.88939867, 0.90867214, 0.88836985, 0.90401978, 0.88625455,\n",
       "         0.25160284, 0.2453001 , 0.2479404 , 0.2340138 , 0.2381392 ,\n",
       "         0.34513078, 0.38917298, 0.33693662, 0.33371902, 0.34706893,\n",
       "         0.43454943, 0.41148229, 0.44483733, 0.48906517, 0.44123859,\n",
       "         0.71527233, 0.70780745, 0.69490104, 0.66818576, 1.83677044,\n",
       "         4.27689757, 4.039288  , 4.16566262, 4.16300921, 3.97855263,\n",
       "         0.97618999, 0.98748899, 0.93428478, 0.98291202, 1.01488075,\n",
       "         1.46809545, 1.50873771, 1.61097503, 1.52410603, 1.47408791,\n",
       "         2.06406822, 2.29088759, 2.5110846 , 2.05265102, 1.99838963,\n",
       "         3.22863007, 2.91671863, 3.20489783, 2.86915126, 2.9749054 ,\n",
       "         3.98122096, 4.19163337, 3.82118087, 3.8485548 , 3.98160701]),\n",
       "  'mean_score_time': array([0.00650973, 0.0019731 , 0.00195103, 0.00196948, 0.00214038,\n",
       "         0.00204859, 0.00236759, 0.00216055, 0.00368762, 0.00211182,\n",
       "         0.00269923, 0.0022378 , 0.00219011, 0.00329738, 0.00256801,\n",
       "         0.00359659, 0.00329499, 0.00328498, 0.00232029, 0.0025898 ,\n",
       "         0.00299258, 0.00364838, 0.00350094, 0.00269737, 0.00315137,\n",
       "         0.00334177, 0.00341835, 0.00261803, 0.00308137, 0.00268927,\n",
       "         0.00211501, 0.00248141, 0.00337243, 0.00364285, 0.00347328,\n",
       "         0.00219321, 0.00248456, 0.00288148, 0.00289717, 0.00297194,\n",
       "         0.0038424 , 0.00341997, 0.00396142, 0.00290732, 0.00324683,\n",
       "         0.00297437, 0.00307426, 0.003157  , 0.004706  , 0.00367875,\n",
       "         0.00198741, 0.00289569, 0.00202932, 0.00237298, 0.00206943,\n",
       "         0.00210147, 0.00267363, 0.00265365, 0.00292091, 0.00289898,\n",
       "         0.00240259, 0.00300422, 0.00258493, 0.00267224, 0.0022768 ,\n",
       "         0.00302439, 0.00275731, 0.00291319, 0.00298681, 0.00290928,\n",
       "         0.00378237, 0.00285082, 0.00335016, 0.00362263, 0.00292549,\n",
       "         0.00316014, 0.00294948, 0.00295682, 0.00203619, 0.00213261,\n",
       "         0.00262818, 0.00343041, 0.00251813, 0.00216384, 0.00245838,\n",
       "         0.00257802, 0.00230422, 0.00290809, 0.00229063, 0.00258365,\n",
       "         0.00354142, 0.00298262, 0.00296922, 0.00268335, 0.01334004,\n",
       "         0.01587257, 0.01695256, 0.01611333, 0.01520476, 0.01455021,\n",
       "         0.01029215, 0.00947943, 0.00822163, 0.01001415, 0.01151123,\n",
       "         0.01095958, 0.01064563, 0.01394696, 0.00921884, 0.01484728,\n",
       "         0.01229525, 0.01337223, 0.01195221, 0.01314621, 0.01052198,\n",
       "         0.01261559, 0.01270995, 0.01492929, 0.01290622, 0.01586485,\n",
       "         0.01401901, 0.01807961, 0.01302972, 0.01727881, 0.01692262]),\n",
       "  'mean_test_score': array([0.87379424, 0.87379424, 0.87379424, 0.87379424, 0.87379424,\n",
       "         0.87466789, 0.87466789, 0.87466789, 0.87466789, 0.87466789,\n",
       "         0.87487284, 0.87487284, 0.87487284, 0.87487284, 0.87487284,\n",
       "         0.87552015, 0.87552015, 0.87552015, 0.87552015, 0.87552015,\n",
       "         0.87513338, 0.87513338, 0.87513338, 0.87513338, 0.87513338,\n",
       "         0.8719414 , 0.8719414 , 0.8719414 , 0.8719414 , 0.8719414 ,\n",
       "         0.87516945, 0.87516945, 0.87516945, 0.87516945, 0.87516945,\n",
       "         0.87615603, 0.87615603, 0.87615603, 0.87615603, 0.87615603,\n",
       "         0.87854306, 0.87854306, 0.87854306, 0.87854306, 0.87854306,\n",
       "         0.87789153, 0.87789153, 0.87789153, 0.87789153, 0.87789153,\n",
       "         0.87133234, 0.87133234, 0.87133234, 0.87133234, 0.87133234,\n",
       "         0.87746348, 0.87746348, 0.87746348, 0.87746348, 0.87746348,\n",
       "         0.87969274, 0.87969274, 0.87969274, 0.87969274, 0.87969274,\n",
       "         0.87910022, 0.87910022, 0.87910022, 0.87910022, 0.87910022,\n",
       "         0.87909084, 0.87909084, 0.87909084, 0.87909084, 0.87909084,\n",
       "         0.87133234, 0.87133234, 0.87133234, 0.87133234, 0.87133234,\n",
       "         0.87727868, 0.87727868, 0.87727868, 0.87727868, 0.87727868,\n",
       "         0.87815402, 0.87815402, 0.87815402, 0.87815402, 0.87815402,\n",
       "         0.8794472 , 0.8794472 , 0.8794472 , 0.8794472 , 0.8794472 ,\n",
       "         0.87821227, 0.87821227, 0.87821227, 0.87821227, 0.87821227,\n",
       "         0.87133234, 0.87133234, 0.87133234, 0.87133234, 0.87133234,\n",
       "         0.87727868, 0.87727868, 0.87727868, 0.87727868, 0.87727868,\n",
       "         0.87815402, 0.87815402, 0.87815402, 0.87815402, 0.87815402,\n",
       "         0.87966086, 0.87966086, 0.87966086, 0.87966086, 0.87966086,\n",
       "         0.87789345, 0.87789345, 0.87789345, 0.87789345, 0.87789345]),\n",
       "  'mean_train_score': array([0.92229895, 0.92229895, 0.92229895, 0.92229895, 0.92229895,\n",
       "         0.92997188, 0.92997188, 0.92997188, 0.92997188, 0.92997188,\n",
       "         0.93777516, 0.93777516, 0.93777516, 0.93777516, 0.93777516,\n",
       "         0.94950809, 0.94950809, 0.94950809, 0.94950809, 0.94950809,\n",
       "         0.95874388, 0.95874388, 0.95874388, 0.95874388, 0.95874388,\n",
       "         0.93555171, 0.93555171, 0.93555171, 0.93555171, 0.93555171,\n",
       "         0.94953897, 0.94953897, 0.94953897, 0.94953897, 0.94953897,\n",
       "         0.95877001, 0.95877001, 0.95877001, 0.95877001, 0.95877001,\n",
       "         0.97190649, 0.97190649, 0.97190649, 0.97190649, 0.97190649,\n",
       "         0.97979662, 0.97979662, 0.97979662, 0.97979662, 0.97979662,\n",
       "         0.93632548, 0.93632548, 0.93632548, 0.93632548, 0.93632548,\n",
       "         0.95243921, 0.95243921, 0.95243921, 0.95243921, 0.95243921,\n",
       "         0.96310737, 0.96310737, 0.96310737, 0.96310737, 0.96310737,\n",
       "         0.97650018, 0.97650018, 0.97650018, 0.97650018, 0.97650018,\n",
       "         0.98321588, 0.98321588, 0.98321588, 0.98321588, 0.98321588,\n",
       "         0.93632548, 0.93632548, 0.93632548, 0.93632548, 0.93632548,\n",
       "         0.95234909, 0.95234909, 0.95234909, 0.95234909, 0.95234909,\n",
       "         0.9634033 , 0.9634033 , 0.9634033 , 0.9634033 , 0.9634033 ,\n",
       "         0.97670069, 0.97670069, 0.97670069, 0.97670069, 0.97670069,\n",
       "         0.98371512, 0.98371512, 0.98371512, 0.98371512, 0.98371512,\n",
       "         0.93632548, 0.93632548, 0.93632548, 0.93632548, 0.93632548,\n",
       "         0.95234909, 0.95234909, 0.95234909, 0.95234909, 0.95234909,\n",
       "         0.9634033 , 0.9634033 , 0.9634033 , 0.9634033 , 0.9634033 ,\n",
       "         0.97675057, 0.97675057, 0.97675057, 0.97675057, 0.97675057,\n",
       "         0.98372174, 0.98372174, 0.98372174, 0.98372174, 0.98372174]),\n",
       "  'param_max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                     5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                     10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                     15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                     20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                     20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "                     25, 25, 25, 25, 25, 25, 25, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 100, 100, 100,\n",
       "                     100, 100, 150, 150, 150, 150, 150, 200, 200, 200, 200,\n",
       "                     200, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 100, 100,\n",
       "                     100, 100, 100, 150, 150, 150, 150, 150, 200, 200, 200,\n",
       "                     200, 200, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75, 100,\n",
       "                     100, 100, 100, 100, 150, 150, 150, 150, 150, 200, 200,\n",
       "                     200, 200, 200, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75,\n",
       "                     100, 100, 100, 100, 100, 150, 150, 150, 150, 150, 200,\n",
       "                     200, 200, 200, 200, 50, 50, 50, 50, 50, 75, 75, 75, 75,\n",
       "                     75, 100, 100, 100, 100, 100, 150, 150, 150, 150, 150,\n",
       "                     200, 200, 200, 200, 200],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1,\n",
       "                     0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2,\n",
       "                     0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3,\n",
       "                     0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4,\n",
       "                     0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
       "                     0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1,\n",
       "                     0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2,\n",
       "                     0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3,\n",
       "                     0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4,\n",
       "                     0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
       "                     0.1, 0.2, 0.3, 0.4, 0.5, 0.1, 0.2, 0.3, 0.4, 0.5, 0.1,\n",
       "                     0.2, 0.3, 0.4, 0.5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 5, 'n_estimators': 50, 'subsample': 0.1},\n",
       "   {'max_depth': 5, 'n_estimators': 50, 'subsample': 0.2},\n",
       "   {'max_depth': 5, 'n_estimators': 50, 'subsample': 0.3},\n",
       "   {'max_depth': 5, 'n_estimators': 50, 'subsample': 0.4},\n",
       "   {'max_depth': 5, 'n_estimators': 50, 'subsample': 0.5},\n",
       "   {'max_depth': 5, 'n_estimators': 75, 'subsample': 0.1},\n",
       "   {'max_depth': 5, 'n_estimators': 75, 'subsample': 0.2},\n",
       "   {'max_depth': 5, 'n_estimators': 75, 'subsample': 0.3},\n",
       "   {'max_depth': 5, 'n_estimators': 75, 'subsample': 0.4},\n",
       "   {'max_depth': 5, 'n_estimators': 75, 'subsample': 0.5},\n",
       "   {'max_depth': 5, 'n_estimators': 100, 'subsample': 0.1},\n",
       "   {'max_depth': 5, 'n_estimators': 100, 'subsample': 0.2},\n",
       "   {'max_depth': 5, 'n_estimators': 100, 'subsample': 0.3},\n",
       "   {'max_depth': 5, 'n_estimators': 100, 'subsample': 0.4},\n",
       "   {'max_depth': 5, 'n_estimators': 100, 'subsample': 0.5},\n",
       "   {'max_depth': 5, 'n_estimators': 150, 'subsample': 0.1},\n",
       "   {'max_depth': 5, 'n_estimators': 150, 'subsample': 0.2},\n",
       "   {'max_depth': 5, 'n_estimators': 150, 'subsample': 0.3},\n",
       "   {'max_depth': 5, 'n_estimators': 150, 'subsample': 0.4},\n",
       "   {'max_depth': 5, 'n_estimators': 150, 'subsample': 0.5},\n",
       "   {'max_depth': 5, 'n_estimators': 200, 'subsample': 0.1},\n",
       "   {'max_depth': 5, 'n_estimators': 200, 'subsample': 0.2},\n",
       "   {'max_depth': 5, 'n_estimators': 200, 'subsample': 0.3},\n",
       "   {'max_depth': 5, 'n_estimators': 200, 'subsample': 0.4},\n",
       "   {'max_depth': 5, 'n_estimators': 200, 'subsample': 0.5},\n",
       "   {'max_depth': 10, 'n_estimators': 50, 'subsample': 0.1},\n",
       "   {'max_depth': 10, 'n_estimators': 50, 'subsample': 0.2},\n",
       "   {'max_depth': 10, 'n_estimators': 50, 'subsample': 0.3},\n",
       "   {'max_depth': 10, 'n_estimators': 50, 'subsample': 0.4},\n",
       "   {'max_depth': 10, 'n_estimators': 50, 'subsample': 0.5},\n",
       "   {'max_depth': 10, 'n_estimators': 75, 'subsample': 0.1},\n",
       "   {'max_depth': 10, 'n_estimators': 75, 'subsample': 0.2},\n",
       "   {'max_depth': 10, 'n_estimators': 75, 'subsample': 0.3},\n",
       "   {'max_depth': 10, 'n_estimators': 75, 'subsample': 0.4},\n",
       "   {'max_depth': 10, 'n_estimators': 75, 'subsample': 0.5},\n",
       "   {'max_depth': 10, 'n_estimators': 100, 'subsample': 0.1},\n",
       "   {'max_depth': 10, 'n_estimators': 100, 'subsample': 0.2},\n",
       "   {'max_depth': 10, 'n_estimators': 100, 'subsample': 0.3},\n",
       "   {'max_depth': 10, 'n_estimators': 100, 'subsample': 0.4},\n",
       "   {'max_depth': 10, 'n_estimators': 100, 'subsample': 0.5},\n",
       "   {'max_depth': 10, 'n_estimators': 150, 'subsample': 0.1},\n",
       "   {'max_depth': 10, 'n_estimators': 150, 'subsample': 0.2},\n",
       "   {'max_depth': 10, 'n_estimators': 150, 'subsample': 0.3},\n",
       "   {'max_depth': 10, 'n_estimators': 150, 'subsample': 0.4},\n",
       "   {'max_depth': 10, 'n_estimators': 150, 'subsample': 0.5},\n",
       "   {'max_depth': 10, 'n_estimators': 200, 'subsample': 0.1},\n",
       "   {'max_depth': 10, 'n_estimators': 200, 'subsample': 0.2},\n",
       "   {'max_depth': 10, 'n_estimators': 200, 'subsample': 0.3},\n",
       "   {'max_depth': 10, 'n_estimators': 200, 'subsample': 0.4},\n",
       "   {'max_depth': 10, 'n_estimators': 200, 'subsample': 0.5},\n",
       "   {'max_depth': 15, 'n_estimators': 50, 'subsample': 0.1},\n",
       "   {'max_depth': 15, 'n_estimators': 50, 'subsample': 0.2},\n",
       "   {'max_depth': 15, 'n_estimators': 50, 'subsample': 0.3},\n",
       "   {'max_depth': 15, 'n_estimators': 50, 'subsample': 0.4},\n",
       "   {'max_depth': 15, 'n_estimators': 50, 'subsample': 0.5},\n",
       "   {'max_depth': 15, 'n_estimators': 75, 'subsample': 0.1},\n",
       "   {'max_depth': 15, 'n_estimators': 75, 'subsample': 0.2},\n",
       "   {'max_depth': 15, 'n_estimators': 75, 'subsample': 0.3},\n",
       "   {'max_depth': 15, 'n_estimators': 75, 'subsample': 0.4},\n",
       "   {'max_depth': 15, 'n_estimators': 75, 'subsample': 0.5},\n",
       "   {'max_depth': 15, 'n_estimators': 100, 'subsample': 0.1},\n",
       "   {'max_depth': 15, 'n_estimators': 100, 'subsample': 0.2},\n",
       "   {'max_depth': 15, 'n_estimators': 100, 'subsample': 0.3},\n",
       "   {'max_depth': 15, 'n_estimators': 100, 'subsample': 0.4},\n",
       "   {'max_depth': 15, 'n_estimators': 100, 'subsample': 0.5},\n",
       "   {'max_depth': 15, 'n_estimators': 150, 'subsample': 0.1},\n",
       "   {'max_depth': 15, 'n_estimators': 150, 'subsample': 0.2},\n",
       "   {'max_depth': 15, 'n_estimators': 150, 'subsample': 0.3},\n",
       "   {'max_depth': 15, 'n_estimators': 150, 'subsample': 0.4},\n",
       "   {'max_depth': 15, 'n_estimators': 150, 'subsample': 0.5},\n",
       "   {'max_depth': 15, 'n_estimators': 200, 'subsample': 0.1},\n",
       "   {'max_depth': 15, 'n_estimators': 200, 'subsample': 0.2},\n",
       "   {'max_depth': 15, 'n_estimators': 200, 'subsample': 0.3},\n",
       "   {'max_depth': 15, 'n_estimators': 200, 'subsample': 0.4},\n",
       "   {'max_depth': 15, 'n_estimators': 200, 'subsample': 0.5},\n",
       "   {'max_depth': 20, 'n_estimators': 50, 'subsample': 0.1},\n",
       "   {'max_depth': 20, 'n_estimators': 50, 'subsample': 0.2},\n",
       "   {'max_depth': 20, 'n_estimators': 50, 'subsample': 0.3},\n",
       "   {'max_depth': 20, 'n_estimators': 50, 'subsample': 0.4},\n",
       "   {'max_depth': 20, 'n_estimators': 50, 'subsample': 0.5},\n",
       "   {'max_depth': 20, 'n_estimators': 75, 'subsample': 0.1},\n",
       "   {'max_depth': 20, 'n_estimators': 75, 'subsample': 0.2},\n",
       "   {'max_depth': 20, 'n_estimators': 75, 'subsample': 0.3},\n",
       "   {'max_depth': 20, 'n_estimators': 75, 'subsample': 0.4},\n",
       "   {'max_depth': 20, 'n_estimators': 75, 'subsample': 0.5},\n",
       "   {'max_depth': 20, 'n_estimators': 100, 'subsample': 0.1},\n",
       "   {'max_depth': 20, 'n_estimators': 100, 'subsample': 0.2},\n",
       "   {'max_depth': 20, 'n_estimators': 100, 'subsample': 0.3},\n",
       "   {'max_depth': 20, 'n_estimators': 100, 'subsample': 0.4},\n",
       "   {'max_depth': 20, 'n_estimators': 100, 'subsample': 0.5},\n",
       "   {'max_depth': 20, 'n_estimators': 150, 'subsample': 0.1},\n",
       "   {'max_depth': 20, 'n_estimators': 150, 'subsample': 0.2},\n",
       "   {'max_depth': 20, 'n_estimators': 150, 'subsample': 0.3},\n",
       "   {'max_depth': 20, 'n_estimators': 150, 'subsample': 0.4},\n",
       "   {'max_depth': 20, 'n_estimators': 150, 'subsample': 0.5},\n",
       "   {'max_depth': 20, 'n_estimators': 200, 'subsample': 0.1},\n",
       "   {'max_depth': 20, 'n_estimators': 200, 'subsample': 0.2},\n",
       "   {'max_depth': 20, 'n_estimators': 200, 'subsample': 0.3},\n",
       "   {'max_depth': 20, 'n_estimators': 200, 'subsample': 0.4},\n",
       "   {'max_depth': 20, 'n_estimators': 200, 'subsample': 0.5},\n",
       "   {'max_depth': 25, 'n_estimators': 50, 'subsample': 0.1},\n",
       "   {'max_depth': 25, 'n_estimators': 50, 'subsample': 0.2},\n",
       "   {'max_depth': 25, 'n_estimators': 50, 'subsample': 0.3},\n",
       "   {'max_depth': 25, 'n_estimators': 50, 'subsample': 0.4},\n",
       "   {'max_depth': 25, 'n_estimators': 50, 'subsample': 0.5},\n",
       "   {'max_depth': 25, 'n_estimators': 75, 'subsample': 0.1},\n",
       "   {'max_depth': 25, 'n_estimators': 75, 'subsample': 0.2},\n",
       "   {'max_depth': 25, 'n_estimators': 75, 'subsample': 0.3},\n",
       "   {'max_depth': 25, 'n_estimators': 75, 'subsample': 0.4},\n",
       "   {'max_depth': 25, 'n_estimators': 75, 'subsample': 0.5},\n",
       "   {'max_depth': 25, 'n_estimators': 100, 'subsample': 0.1},\n",
       "   {'max_depth': 25, 'n_estimators': 100, 'subsample': 0.2},\n",
       "   {'max_depth': 25, 'n_estimators': 100, 'subsample': 0.3},\n",
       "   {'max_depth': 25, 'n_estimators': 100, 'subsample': 0.4},\n",
       "   {'max_depth': 25, 'n_estimators': 100, 'subsample': 0.5},\n",
       "   {'max_depth': 25, 'n_estimators': 150, 'subsample': 0.1},\n",
       "   {'max_depth': 25, 'n_estimators': 150, 'subsample': 0.2},\n",
       "   {'max_depth': 25, 'n_estimators': 150, 'subsample': 0.3},\n",
       "   {'max_depth': 25, 'n_estimators': 150, 'subsample': 0.4},\n",
       "   {'max_depth': 25, 'n_estimators': 150, 'subsample': 0.5},\n",
       "   {'max_depth': 25, 'n_estimators': 200, 'subsample': 0.1},\n",
       "   {'max_depth': 25, 'n_estimators': 200, 'subsample': 0.2},\n",
       "   {'max_depth': 25, 'n_estimators': 200, 'subsample': 0.3},\n",
       "   {'max_depth': 25, 'n_estimators': 200, 'subsample': 0.4},\n",
       "   {'max_depth': 25, 'n_estimators': 200, 'subsample': 0.5}],\n",
       "  'rank_test_score': array([101, 101, 101, 101, 101,  96,  96,  96,  96,  96,  91,  91,  91,\n",
       "          91,  91,  76,  76,  76,  76,  76,  86,  86,  86,  86,  86, 106,\n",
       "         106, 106, 106, 106,  81,  81,  81,  81,  81,  71,  71,  71,  71,\n",
       "          71,  26,  26,  26,  26,  26,  51,  51,  51,  51,  51, 111, 111,\n",
       "         111, 111, 111,  56,  56,  56,  56,  56,   1,   1,   1,   1,   1,\n",
       "          16,  16,  16,  16,  16,  21,  21,  21,  21,  21, 111, 111, 111,\n",
       "         111, 111,  61,  61,  61,  61,  61,  36,  36,  36,  36,  36,  11,\n",
       "          11,  11,  11,  11,  31,  31,  31,  31,  31, 111, 111, 111, 111,\n",
       "         111,  61,  61,  61,  61,  61,  36,  36,  36,  36,  36,   6,   6,\n",
       "           6,   6,   6,  46,  46,  46,  46,  46], dtype=int32),\n",
       "  'split0_test_score': array([0.83386034, 0.83386034, 0.83386034, 0.83386034, 0.83386034,\n",
       "         0.83194993, 0.83194993, 0.83194993, 0.83194993, 0.83194993,\n",
       "         0.83109354, 0.83109354, 0.83109354, 0.83109354, 0.83109354,\n",
       "         0.82523057, 0.82523057, 0.82523057, 0.82523057, 0.82523057,\n",
       "         0.828722  , 0.828722  , 0.828722  , 0.828722  , 0.828722  ,\n",
       "         0.83320158, 0.83320158, 0.83320158, 0.83320158, 0.83320158,\n",
       "         0.83610013, 0.83610013, 0.83610013, 0.83610013, 0.83610013,\n",
       "         0.83570487, 0.83570487, 0.83570487, 0.83570487, 0.83570487,\n",
       "         0.84183136, 0.84183136, 0.84183136, 0.84183136, 0.84183136,\n",
       "         0.84288538, 0.84288538, 0.84288538, 0.84288538, 0.84288538,\n",
       "         0.83491436, 0.83491436, 0.83491436, 0.83491436, 0.83491436,\n",
       "         0.84459816, 0.84459816, 0.84459816, 0.84459816, 0.84459816,\n",
       "         0.84578393, 0.84578393, 0.84578393, 0.84578393, 0.84578393,\n",
       "         0.84617918, 0.84617918, 0.84617918, 0.84617918, 0.84617918,\n",
       "         0.84670619, 0.84670619, 0.84670619, 0.84670619, 0.84670619,\n",
       "         0.83491436, 0.83491436, 0.83491436, 0.83491436, 0.83491436,\n",
       "         0.8444664 , 0.8444664 , 0.8444664 , 0.8444664 , 0.8444664 ,\n",
       "         0.84354414, 0.84354414, 0.84354414, 0.84354414, 0.84354414,\n",
       "         0.84855072, 0.84855072, 0.84855072, 0.84855072, 0.84855072,\n",
       "         0.85079051, 0.85079051, 0.85079051, 0.85079051, 0.85079051,\n",
       "         0.83491436, 0.83491436, 0.83491436, 0.83491436, 0.83491436,\n",
       "         0.8444664 , 0.8444664 , 0.8444664 , 0.8444664 , 0.8444664 ,\n",
       "         0.84354414, 0.84354414, 0.84354414, 0.84354414, 0.84354414,\n",
       "         0.84855072, 0.84855072, 0.84855072, 0.84855072, 0.84855072,\n",
       "         0.84986825, 0.84986825, 0.84986825, 0.84986825, 0.84986825]),\n",
       "  'split0_train_score': array([0.93470425, 0.93470425, 0.93470425, 0.93470425, 0.93470425,\n",
       "         0.94197602, 0.94197602, 0.94197602, 0.94197602, 0.94197602,\n",
       "         0.94651097, 0.94651097, 0.94651097, 0.94651097, 0.94651097,\n",
       "         0.95679074, 0.95679074, 0.95679074, 0.95679074, 0.95679074,\n",
       "         0.96310296, 0.96310296, 0.96310296, 0.96310296, 0.96310296,\n",
       "         0.94170901, 0.94170901, 0.94170901, 0.94170901, 0.94170901,\n",
       "         0.95376605, 0.95376605, 0.95376605, 0.95376605, 0.95376605,\n",
       "         0.96228108, 0.96228108, 0.96228108, 0.96228108, 0.96228108,\n",
       "         0.97322837, 0.97322837, 0.97322837, 0.97322837, 0.97322837,\n",
       "         0.97946966, 0.97946966, 0.97946966, 0.97946966, 0.97946966,\n",
       "         0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 ,\n",
       "         0.95332382, 0.95332382, 0.95332382, 0.95332382, 0.95332382,\n",
       "         0.9634242 , 0.9634242 , 0.9634242 , 0.9634242 , 0.9634242 ,\n",
       "         0.97597353, 0.97597353, 0.97597353, 0.97597353, 0.97597353,\n",
       "         0.98173087, 0.98173087, 0.98173087, 0.98173087, 0.98173087,\n",
       "         0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 ,\n",
       "         0.95338223, 0.95338223, 0.95338223, 0.95338223, 0.95338223,\n",
       "         0.96450057, 0.96450057, 0.96450057, 0.96450057, 0.96450057,\n",
       "         0.97573156, 0.97573156, 0.97573156, 0.97573156, 0.97573156,\n",
       "         0.98189775, 0.98189775, 0.98189775, 0.98189775, 0.98189775,\n",
       "         0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 , 0.9415922 ,\n",
       "         0.95338223, 0.95338223, 0.95338223, 0.95338223, 0.95338223,\n",
       "         0.96450057, 0.96450057, 0.96450057, 0.96450057, 0.96450057,\n",
       "         0.97573156, 0.97573156, 0.97573156, 0.97573156, 0.97573156,\n",
       "         0.98184769, 0.98184769, 0.98184769, 0.98184769, 0.98184769]),\n",
       "  'split1_test_score': array([0.82345191, 0.82345191, 0.82345191, 0.82345191, 0.82345191,\n",
       "         0.82529644, 0.82529644, 0.82529644, 0.82529644, 0.82529644,\n",
       "         0.83056653, 0.83056653, 0.83056653, 0.83056653, 0.83056653,\n",
       "         0.83787879, 0.83787879, 0.83787879, 0.83787879, 0.83787879,\n",
       "         0.83781291, 0.83781291, 0.83781291, 0.83781291, 0.83781291,\n",
       "         0.82140975, 0.82140975, 0.82140975, 0.82140975, 0.82140975,\n",
       "         0.82661397, 0.82661397, 0.82661397, 0.82661397, 0.82661397,\n",
       "         0.82779974, 0.82779974, 0.82779974, 0.82779974, 0.82779974,\n",
       "         0.83636364, 0.83636364, 0.83636364, 0.83636364, 0.83636364,\n",
       "         0.83899868, 0.83899868, 0.83899868, 0.83899868, 0.83899868,\n",
       "         0.81640316, 0.81640316, 0.81640316, 0.81640316, 0.81640316,\n",
       "         0.82740448, 0.82740448, 0.82740448, 0.82740448, 0.82740448,\n",
       "         0.83306983, 0.83306983, 0.83306983, 0.83306983, 0.83306983,\n",
       "         0.8345191 , 0.8345191 , 0.8345191 , 0.8345191 , 0.8345191 ,\n",
       "         0.83807642, 0.83807642, 0.83807642, 0.83807642, 0.83807642,\n",
       "         0.81640316, 0.81640316, 0.81640316, 0.81640316, 0.81640316,\n",
       "         0.82635046, 0.82635046, 0.82635046, 0.82635046, 0.82635046,\n",
       "         0.82924901, 0.82924901, 0.82924901, 0.82924901, 0.82924901,\n",
       "         0.83201581, 0.83201581, 0.83201581, 0.83201581, 0.83201581,\n",
       "         0.83188406, 0.83188406, 0.83188406, 0.83188406, 0.83188406,\n",
       "         0.81640316, 0.81640316, 0.81640316, 0.81640316, 0.81640316,\n",
       "         0.82635046, 0.82635046, 0.82635046, 0.82635046, 0.82635046,\n",
       "         0.82924901, 0.82924901, 0.82924901, 0.82924901, 0.82924901,\n",
       "         0.83201581, 0.83201581, 0.83201581, 0.83201581, 0.83201581,\n",
       "         0.83188406, 0.83188406, 0.83188406, 0.83188406, 0.83188406]),\n",
       "  'split1_train_score': array([0.92768697, 0.92768697, 0.92768697, 0.92768697, 0.92768697,\n",
       "         0.93462915, 0.93462915, 0.93462915, 0.93462915, 0.93462915,\n",
       "         0.94200522, 0.94200522, 0.94200522, 0.94200522, 0.94200522,\n",
       "         0.95398299, 0.95398299, 0.95398299, 0.95398299, 0.95398299,\n",
       "         0.96367035, 0.96367035, 0.96367035, 0.96367035, 0.96367035,\n",
       "         0.94171736, 0.94171736, 0.94171736, 0.94171736, 0.94171736,\n",
       "         0.9549801 , 0.9549801 , 0.9549801 , 0.9549801 , 0.9549801 ,\n",
       "         0.96362445, 0.96362445, 0.96362445, 0.96362445, 0.96362445,\n",
       "         0.97621968, 0.97621968, 0.97621968, 0.97621968, 0.97621968,\n",
       "         0.98380018, 0.98380018, 0.98380018, 0.98380018, 0.98380018,\n",
       "         0.94272698, 0.94272698, 0.94272698, 0.94272698, 0.94272698,\n",
       "         0.95883501, 0.95883501, 0.95883501, 0.95883501, 0.95883501,\n",
       "         0.96867673, 0.96867673, 0.96867673, 0.96867673, 0.96867673,\n",
       "         0.98128864, 0.98128864, 0.98128864, 0.98128864, 0.98128864,\n",
       "         0.98694586, 0.98694586, 0.98694586, 0.98694586, 0.98694586,\n",
       "         0.94272698, 0.94272698, 0.94272698, 0.94272698, 0.94272698,\n",
       "         0.95832603, 0.95832603, 0.95832603, 0.95832603, 0.95832603,\n",
       "         0.96889367, 0.96889367, 0.96889367, 0.96889367, 0.96889367,\n",
       "         0.98179345, 0.98179345, 0.98179345, 0.98179345, 0.98179345,\n",
       "         0.98767595, 0.98767595, 0.98767595, 0.98767595, 0.98767595,\n",
       "         0.94272698, 0.94272698, 0.94272698, 0.94272698, 0.94272698,\n",
       "         0.95832603, 0.95832603, 0.95832603, 0.95832603, 0.95832603,\n",
       "         0.96889367, 0.96889367, 0.96889367, 0.96889367, 0.96889367,\n",
       "         0.98179345, 0.98179345, 0.98179345, 0.98179345, 0.98179345,\n",
       "         0.98767595, 0.98767595, 0.98767595, 0.98767595, 0.98767595]),\n",
       "  'split2_test_score': array([0.91684492, 0.91684492, 0.91684492, 0.91684492, 0.91684492,\n",
       "         0.91504011, 0.91504011, 0.91504011, 0.91504011, 0.91504011,\n",
       "         0.9151738 , 0.9151738 , 0.9151738 , 0.9151738 , 0.9151738 ,\n",
       "         0.92065508, 0.92065508, 0.92065508, 0.92065508, 0.92065508,\n",
       "         0.92372995, 0.92372995, 0.92372995, 0.92372995, 0.92372995,\n",
       "         0.91590909, 0.91590909, 0.91590909, 0.91590909, 0.91590909,\n",
       "         0.9236631 , 0.9236631 , 0.9236631 , 0.9236631 , 0.9236631 ,\n",
       "         0.92754011, 0.92754011, 0.92754011, 0.92754011, 0.92754011,\n",
       "         0.93248663, 0.93248663, 0.93248663, 0.93248663, 0.93248663,\n",
       "         0.93435829, 0.93435829, 0.93435829, 0.93435829, 0.93435829,\n",
       "         0.91791444, 0.91791444, 0.91791444, 0.91791444, 0.91791444,\n",
       "         0.92352941, 0.92352941, 0.92352941, 0.92352941, 0.92352941,\n",
       "         0.92994652, 0.92994652, 0.92994652, 0.92994652, 0.92994652,\n",
       "         0.92967914, 0.92967914, 0.92967914, 0.92967914, 0.92967914,\n",
       "         0.92754011, 0.92754011, 0.92754011, 0.92754011, 0.92754011,\n",
       "         0.91791444, 0.91791444, 0.91791444, 0.91791444, 0.91791444,\n",
       "         0.92379679, 0.92379679, 0.92379679, 0.92379679, 0.92379679,\n",
       "         0.92740642, 0.92740642, 0.92740642, 0.92740642, 0.92740642,\n",
       "         0.93181818, 0.93181818, 0.93181818, 0.93181818, 0.93181818,\n",
       "         0.92740642, 0.92740642, 0.92740642, 0.92740642, 0.92740642,\n",
       "         0.91791444, 0.91791444, 0.91791444, 0.91791444, 0.91791444,\n",
       "         0.92379679, 0.92379679, 0.92379679, 0.92379679, 0.92379679,\n",
       "         0.92740642, 0.92740642, 0.92740642, 0.92740642, 0.92740642,\n",
       "         0.93181818, 0.93181818, 0.93181818, 0.93181818, 0.93181818,\n",
       "         0.92740642, 0.92740642, 0.92740642, 0.92740642, 0.92740642]),\n",
       "  'split2_train_score': array([0.91301565, 0.91301565, 0.91301565, 0.91301565, 0.91301565,\n",
       "         0.91853998, 0.91853998, 0.91853998, 0.91853998, 0.91853998,\n",
       "         0.92632559, 0.92632559, 0.92632559, 0.92632559, 0.92632559,\n",
       "         0.93680894, 0.93680894, 0.93680894, 0.93680894, 0.93680894,\n",
       "         0.9483772 , 0.9483772 , 0.9483772 , 0.9483772 , 0.9483772 ,\n",
       "         0.92824186, 0.92824186, 0.92824186, 0.92824186, 0.92824186,\n",
       "         0.93933209, 0.93933209, 0.93933209, 0.93933209, 0.93933209,\n",
       "         0.94853516, 0.94853516, 0.94853516, 0.94853516, 0.94853516,\n",
       "         0.96423524, 0.96423524, 0.96423524, 0.96423524, 0.96423524,\n",
       "         0.97489317, 0.97489317, 0.97489317, 0.97489317, 0.97489317,\n",
       "         0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 ,\n",
       "         0.94422044, 0.94422044, 0.94422044, 0.94422044, 0.94422044,\n",
       "         0.95550604, 0.95550604, 0.95550604, 0.95550604, 0.95550604,\n",
       "         0.97170078, 0.97170078, 0.97170078, 0.97170078, 0.97170078,\n",
       "         0.97968176, 0.97968176, 0.97968176, 0.97968176, 0.97968176,\n",
       "         0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 ,\n",
       "         0.94426201, 0.94426201, 0.94426201, 0.94426201, 0.94426201,\n",
       "         0.9550197 , 0.9550197 , 0.9550197 , 0.9550197 , 0.9550197 ,\n",
       "         0.97118118, 0.97118118, 0.97118118, 0.97118118, 0.97118118,\n",
       "         0.98021798, 0.98021798, 0.98021798, 0.98021798, 0.98021798,\n",
       "         0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 , 0.9289776 ,\n",
       "         0.94426201, 0.94426201, 0.94426201, 0.94426201, 0.94426201,\n",
       "         0.9550197 , 0.9550197 , 0.9550197 , 0.9550197 , 0.9550197 ,\n",
       "         0.97118118, 0.97118118, 0.97118118, 0.97118118, 0.97118118,\n",
       "         0.98021798, 0.98021798, 0.98021798, 0.98021798, 0.98021798]),\n",
       "  'split3_test_score': array([0.88001337, 0.88001337, 0.88001337, 0.88001337, 0.88001337,\n",
       "         0.87834225, 0.87834225, 0.87834225, 0.87834225, 0.87834225,\n",
       "         0.87580214, 0.87580214, 0.87580214, 0.87580214, 0.87580214,\n",
       "         0.87840909, 0.87840909, 0.87840909, 0.87840909, 0.87840909,\n",
       "         0.87947861, 0.87947861, 0.87947861, 0.87947861, 0.87947861,\n",
       "         0.87660428, 0.87660428, 0.87660428, 0.87660428, 0.87660428,\n",
       "         0.88008021, 0.88008021, 0.88008021, 0.88008021, 0.88008021,\n",
       "         0.88061497, 0.88061497, 0.88061497, 0.88061497, 0.88061497,\n",
       "         0.8776738 , 0.8776738 , 0.8776738 , 0.8776738 , 0.8776738 ,\n",
       "         0.87433155, 0.87433155, 0.87433155, 0.87433155, 0.87433155,\n",
       "         0.87593583, 0.87593583, 0.87593583, 0.87593583, 0.87593583,\n",
       "         0.88141711, 0.88141711, 0.88141711, 0.88141711, 0.88141711,\n",
       "         0.88181818, 0.88181818, 0.88181818, 0.88181818, 0.88181818,\n",
       "         0.87954545, 0.87954545, 0.87954545, 0.87954545, 0.87954545,\n",
       "         0.88034759, 0.88034759, 0.88034759, 0.88034759, 0.88034759,\n",
       "         0.87593583, 0.87593583, 0.87593583, 0.87593583, 0.87593583,\n",
       "         0.88141711, 0.88141711, 0.88141711, 0.88141711, 0.88141711,\n",
       "         0.88368984, 0.88368984, 0.88368984, 0.88368984, 0.88368984,\n",
       "         0.87994652, 0.87994652, 0.87994652, 0.87994652, 0.87994652,\n",
       "         0.87967914, 0.87967914, 0.87967914, 0.87967914, 0.87967914,\n",
       "         0.87593583, 0.87593583, 0.87593583, 0.87593583, 0.87593583,\n",
       "         0.88141711, 0.88141711, 0.88141711, 0.88141711, 0.88141711,\n",
       "         0.88368984, 0.88368984, 0.88368984, 0.88368984, 0.88368984,\n",
       "         0.88101604, 0.88101604, 0.88101604, 0.88101604, 0.88101604,\n",
       "         0.8790107 , 0.8790107 , 0.8790107 , 0.8790107 , 0.8790107 ]),\n",
       "  'split3_train_score': array([0.9188268 , 0.9188268 , 0.9188268 , 0.9188268 , 0.9188268 ,\n",
       "         0.92828342, 0.92828342, 0.92828342, 0.92828342, 0.92828342,\n",
       "         0.93628103, 0.93628103, 0.93628103, 0.93628103, 0.93628103,\n",
       "         0.9504057 , 0.9504057 , 0.9504057 , 0.9504057 , 0.9504057 ,\n",
       "         0.95862777, 0.95862777, 0.95862777, 0.95862777, 0.95862777,\n",
       "         0.93558269, 0.93558269, 0.93558269, 0.93558269, 0.93558269,\n",
       "         0.94991936, 0.94991936, 0.94991936, 0.94991936, 0.94991936,\n",
       "         0.95983739, 0.95983739, 0.95983739, 0.95983739, 0.95983739,\n",
       "         0.97289793, 0.97289793, 0.97289793, 0.97289793, 0.97289793,\n",
       "         0.97981477, 0.97981477, 0.97981477, 0.97981477, 0.97981477,\n",
       "         0.93591524, 0.93591524, 0.93591524, 0.93591524, 0.93591524,\n",
       "         0.95353158, 0.95353158, 0.95353158, 0.95353158, 0.95353158,\n",
       "         0.96432669, 0.96432669, 0.96432669, 0.96432669, 0.96432669,\n",
       "         0.97639792, 0.97639792, 0.97639792, 0.97639792, 0.97639792,\n",
       "         0.98333139, 0.98333139, 0.98333139, 0.98333139, 0.98333139,\n",
       "         0.93591524, 0.93591524, 0.93591524, 0.93591524, 0.93591524,\n",
       "         0.95349002, 0.95349002, 0.95349002, 0.95349002, 0.95349002,\n",
       "         0.96467586, 0.96467586, 0.96467586, 0.96467586, 0.96467586,\n",
       "         0.97757844, 0.97757844, 0.97757844, 0.97757844, 0.97757844,\n",
       "         0.98390503, 0.98390503, 0.98390503, 0.98390503, 0.98390503,\n",
       "         0.93591524, 0.93591524, 0.93591524, 0.93591524, 0.93591524,\n",
       "         0.95349002, 0.95349002, 0.95349002, 0.95349002, 0.95349002,\n",
       "         0.96467586, 0.96467586, 0.96467586, 0.96467586, 0.96467586,\n",
       "         0.97782784, 0.97782784, 0.97782784, 0.97782784, 0.97782784,\n",
       "         0.98398816, 0.98398816, 0.98398816, 0.98398816, 0.98398816]),\n",
       "  'split4_test_score': array([0.91554236, 0.91554236, 0.91554236, 0.91554236, 0.91554236,\n",
       "         0.92350243, 0.92350243, 0.92350243, 0.92350243, 0.92350243,\n",
       "         0.92249056, 0.92249056, 0.92249056, 0.92249056, 0.92249056,\n",
       "         0.91614949, 0.91614949, 0.91614949, 0.91614949, 0.91614949,\n",
       "         0.90657043, 0.90657043, 0.90657043, 0.90657043, 0.90657043,\n",
       "         0.91331624, 0.91331624, 0.91331624, 0.91331624, 0.91331624,\n",
       "         0.91007825, 0.91007825, 0.91007825, 0.91007825, 0.91007825,\n",
       "         0.90980842, 0.90980842, 0.90980842, 0.90980842, 0.90980842,\n",
       "         0.90495143, 0.90495143, 0.90495143, 0.90495143, 0.90495143,\n",
       "         0.89941986, 0.89941986, 0.89941986, 0.89941986, 0.89941986,\n",
       "         0.91223691, 0.91223691, 0.91223691, 0.91223691, 0.91223691,\n",
       "         0.91102267, 0.91102267, 0.91102267, 0.91102267, 0.91102267,\n",
       "         0.90845926, 0.90845926, 0.90845926, 0.90845926, 0.90845926,\n",
       "         0.90616568, 0.90616568, 0.90616568, 0.90616568, 0.90616568,\n",
       "         0.90333243, 0.90333243, 0.90333243, 0.90333243, 0.90333243,\n",
       "         0.91223691, 0.91223691, 0.91223691, 0.91223691, 0.91223691,\n",
       "         0.91102267, 0.91102267, 0.91102267, 0.91102267, 0.91102267,\n",
       "         0.90751484, 0.90751484, 0.90751484, 0.90751484, 0.90751484,\n",
       "         0.9054911 , 0.9054911 , 0.9054911 , 0.9054911 , 0.9054911 ,\n",
       "         0.90184835, 0.90184835, 0.90184835, 0.90184835, 0.90184835,\n",
       "         0.91223691, 0.91223691, 0.91223691, 0.91223691, 0.91223691,\n",
       "         0.91102267, 0.91102267, 0.91102267, 0.91102267, 0.91102267,\n",
       "         0.90751484, 0.90751484, 0.90751484, 0.90751484, 0.90751484,\n",
       "         0.9054911 , 0.9054911 , 0.9054911 , 0.9054911 , 0.9054911 ,\n",
       "         0.90184835, 0.90184835, 0.90184835, 0.90184835, 0.90184835]),\n",
       "  'split4_train_score': array([0.91726111, 0.91726111, 0.91726111, 0.91726111, 0.91726111,\n",
       "         0.92643082, 0.92643082, 0.92643082, 0.92643082, 0.92643082,\n",
       "         0.93775299, 0.93775299, 0.93775299, 0.93775299, 0.93775299,\n",
       "         0.94955209, 0.94955209, 0.94955209, 0.94955209, 0.94955209,\n",
       "         0.95994111, 0.95994111, 0.95994111, 0.95994111, 0.95994111,\n",
       "         0.93050763, 0.93050763, 0.93050763, 0.93050763, 0.93050763,\n",
       "         0.94969725, 0.94969725, 0.94969725, 0.94969725, 0.94969725,\n",
       "         0.959572  , 0.959572  , 0.959572  , 0.959572  , 0.959572  ,\n",
       "         0.97295123, 0.97295123, 0.97295123, 0.97295123, 0.97295123,\n",
       "         0.98100531, 0.98100531, 0.98100531, 0.98100531, 0.98100531,\n",
       "         0.93241539, 0.93241539, 0.93241539, 0.93241539, 0.93241539,\n",
       "         0.95228517, 0.95228517, 0.95228517, 0.95228517, 0.95228517,\n",
       "         0.96360319, 0.96360319, 0.96360319, 0.96360319, 0.96360319,\n",
       "         0.97714001, 0.97714001, 0.97714001, 0.97714001, 0.97714001,\n",
       "         0.98438952, 0.98438952, 0.98438952, 0.98438952, 0.98438952,\n",
       "         0.93241539, 0.93241539, 0.93241539, 0.93241539, 0.93241539,\n",
       "         0.95228517, 0.95228517, 0.95228517, 0.95228517, 0.95228517,\n",
       "         0.96392668, 0.96392668, 0.96392668, 0.96392668, 0.96392668,\n",
       "         0.97721881, 0.97721881, 0.97721881, 0.97721881, 0.97721881,\n",
       "         0.9848789 , 0.9848789 , 0.9848789 , 0.9848789 , 0.9848789 ,\n",
       "         0.93241539, 0.93241539, 0.93241539, 0.93241539, 0.93241539,\n",
       "         0.95228517, 0.95228517, 0.95228517, 0.95228517, 0.95228517,\n",
       "         0.96392668, 0.96392668, 0.96392668, 0.96392668, 0.96392668,\n",
       "         0.97721881, 0.97721881, 0.97721881, 0.97721881, 0.97721881,\n",
       "         0.9848789 , 0.9848789 , 0.9848789 , 0.9848789 , 0.9848789 ]),\n",
       "  'std_fit_time': array([0.01329954, 0.00973573, 0.00677824, 0.01599519, 0.00920941,\n",
       "         0.01135607, 0.0088793 , 0.08008872, 0.03933334, 0.02769136,\n",
       "         0.02210953, 0.01049979, 0.02094018, 0.04737553, 0.05354054,\n",
       "         0.01992999, 0.03321109, 0.03187114, 0.05926089, 0.02414157,\n",
       "         0.04193658, 0.02685208, 0.02643386, 0.03706848, 0.06328642,\n",
       "         0.02160906, 0.03546101, 0.01069205, 0.02057505, 0.04007178,\n",
       "         0.03912523, 0.02980152, 0.0456944 , 0.02303191, 0.01864768,\n",
       "         0.02284544, 0.02420772, 0.03799835, 0.03163979, 0.0204185 ,\n",
       "         0.06304723, 0.05515228, 0.05340089, 0.03430415, 0.01554221,\n",
       "         0.04765833, 0.06500052, 0.05819052, 0.08352462, 0.01571152,\n",
       "         0.00533328, 0.01139784, 0.01215559, 0.01061718, 0.0049528 ,\n",
       "         0.01693281, 0.02121826, 0.03253942, 0.01048531, 0.01683953,\n",
       "         0.02576731, 0.01433631, 0.03439734, 0.02874316, 0.02844995,\n",
       "         0.02756277, 0.03954911, 0.04318889, 0.03099368, 0.03226075,\n",
       "         0.04279128, 0.06450816, 0.03668366, 0.07199154, 0.01733299,\n",
       "         0.00686985, 0.01823805, 0.0178318 , 0.01398683, 0.01270523,\n",
       "         0.02296604, 0.02233432, 0.0261416 , 0.02302911, 0.02165718,\n",
       "         0.02294095, 0.01343391, 0.03702873, 0.01986004, 0.01636008,\n",
       "         0.03127924, 0.02028198, 0.03357152, 0.05130137, 1.14383245,\n",
       "         0.26545687, 0.12186075, 0.49985278, 0.24270147, 0.24455504,\n",
       "         0.03205505, 0.0470157 , 0.03072314, 0.04545025, 0.04227753,\n",
       "         0.0555113 , 0.02877475, 0.09581672, 0.07840451, 0.05999372,\n",
       "         0.21953221, 0.38505644, 0.63472928, 0.12173125, 0.04538011,\n",
       "         0.25425192, 0.09503882, 0.25509617, 0.0702262 , 0.14112328,\n",
       "         0.36300238, 0.33670144, 0.10496082, 0.0930263 , 0.14116261]),\n",
       "  'std_score_time': array([8.60670959e-03, 1.00978462e-04, 2.62058354e-05, 3.34403965e-05,\n",
       "         8.23077568e-05, 6.27146194e-05, 3.48901674e-04, 1.97657946e-04,\n",
       "         1.41257465e-03, 1.67986733e-04, 8.16161250e-04, 1.29929595e-04,\n",
       "         4.67271220e-05, 1.35336568e-03, 5.18214702e-04, 1.01246168e-03,\n",
       "         1.32977518e-03, 1.60951260e-03, 1.55212216e-04, 3.81252125e-04,\n",
       "         7.08804143e-04, 1.56395216e-03, 1.32627926e-03, 4.77645584e-04,\n",
       "         1.06045368e-03, 1.64932884e-03, 2.72346753e-03, 8.13238293e-04,\n",
       "         1.71706428e-03, 6.29716405e-04, 3.67099583e-05, 2.76422316e-04,\n",
       "         1.21630433e-03, 1.34052571e-03, 1.79079781e-03, 3.10526814e-05,\n",
       "         2.43700038e-04, 6.93060844e-04, 9.45228426e-04, 9.74264452e-04,\n",
       "         1.51024545e-03, 1.16321332e-03, 8.59248712e-04, 5.24536380e-04,\n",
       "         8.43009357e-04, 4.70129823e-04, 6.62370918e-04, 8.14206528e-04,\n",
       "         2.54992599e-03, 1.03033187e-03, 3.93771652e-05, 1.18523798e-03,\n",
       "         6.91845529e-05, 6.74812325e-04, 9.45786279e-05, 7.66608832e-05,\n",
       "         6.45058216e-04, 6.96240325e-04, 1.67822195e-03, 9.31506013e-04,\n",
       "         2.56044211e-04, 6.06593761e-04, 4.79820219e-04, 7.63457858e-04,\n",
       "         1.25559527e-04, 7.09682373e-04, 3.01294795e-04, 6.49465153e-04,\n",
       "         6.78368434e-04, 3.87362815e-04, 8.74550685e-04, 1.37907819e-04,\n",
       "         6.89658907e-04, 8.40295472e-04, 2.39771656e-04, 8.99572561e-04,\n",
       "         1.21449657e-03, 1.21430720e-03, 8.98013128e-05, 1.82193819e-04,\n",
       "         9.76566931e-04, 1.29663678e-03, 6.76317935e-04, 1.09697256e-04,\n",
       "         3.56996978e-04, 7.70003134e-04, 1.26905495e-04, 8.48656585e-04,\n",
       "         9.17475584e-05, 6.76061341e-04, 1.73226102e-03, 6.26192970e-04,\n",
       "         6.88740914e-04, 1.50044099e-04, 9.19362224e-03, 4.55374838e-03,\n",
       "         4.17787599e-03, 3.37370999e-03, 5.38556874e-03, 2.98388232e-03,\n",
       "         1.13721054e-03, 1.69303665e-03, 1.80972950e-03, 4.79588363e-03,\n",
       "         4.11793642e-03, 2.41557379e-03, 2.13660499e-03, 7.44066973e-03,\n",
       "         7.52199132e-04, 8.87334486e-03, 3.48843068e-03, 3.29400639e-03,\n",
       "         1.61723032e-03, 4.07547422e-03, 1.60703747e-03, 3.73879449e-03,\n",
       "         2.99465989e-03, 2.92887491e-03, 4.38399065e-03, 1.17684071e-02,\n",
       "         6.20486026e-04, 3.11770593e-03, 1.55944716e-03, 7.41153721e-03,\n",
       "         8.71008336e-03]),\n",
       "  'std_test_score': array([0.03941748, 0.03941748, 0.03941748, 0.03941748, 0.03941748,\n",
       "         0.04072303, 0.04072303, 0.04072303, 0.04072303, 0.04072303,\n",
       "         0.03942709, 0.03942709, 0.03942709, 0.03942709, 0.03942709,\n",
       "         0.03910618, 0.03910618, 0.03910618, 0.03910618, 0.03910618,\n",
       "         0.03720813, 0.03720813, 0.03720813, 0.03720813, 0.03720813,\n",
       "         0.0393077 , 0.0393077 , 0.0393077 , 0.0393077 , 0.0393077 ,\n",
       "         0.03869105, 0.03869105, 0.03869105, 0.03869105, 0.03869105,\n",
       "         0.03943234, 0.03943234, 0.03943234, 0.03943234, 0.03943234,\n",
       "         0.03671783, 0.03671783, 0.03671783, 0.03671783, 0.03671783,\n",
       "         0.03580028, 0.03580028, 0.03580028, 0.03580028, 0.03580028,\n",
       "         0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 ,\n",
       "         0.0370299 , 0.0370299 , 0.0370299 , 0.0370299 , 0.0370299 ,\n",
       "         0.03657181, 0.03657181, 0.03657181, 0.03657181, 0.03657181,\n",
       "         0.03568815, 0.03568815, 0.03568815, 0.03568815, 0.03568815,\n",
       "         0.03368436, 0.03368436, 0.03368436, 0.03368436, 0.03368436,\n",
       "         0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 ,\n",
       "         0.03740697, 0.03740697, 0.03740697, 0.03740697, 0.03740697,\n",
       "         0.03719032, 0.03719032, 0.03719032, 0.03719032, 0.03719032,\n",
       "         0.03642066, 0.03642066, 0.03642066, 0.03642066, 0.03642066,\n",
       "         0.03430938, 0.03430938, 0.03430938, 0.03430938, 0.03430938,\n",
       "         0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 , 0.0405303 ,\n",
       "         0.03740697, 0.03740697, 0.03740697, 0.03740697, 0.03740697,\n",
       "         0.03719032, 0.03719032, 0.03719032, 0.03719032, 0.03719032,\n",
       "         0.0364261 , 0.0364261 , 0.0364261 , 0.0364261 , 0.0364261 ,\n",
       "         0.03445376, 0.03445376, 0.03445376, 0.03445376, 0.03445376]),\n",
       "  'std_train_score': array([0.00782991, 0.00782991, 0.00782991, 0.00782991, 0.00782991,\n",
       "         0.00789769, 0.00789769, 0.00789769, 0.00789769, 0.00789769,\n",
       "         0.00674586, 0.00674586, 0.00674586, 0.00674586, 0.00674586,\n",
       "         0.00685767, 0.00685767, 0.00685767, 0.00685767, 0.00685767,\n",
       "         0.005517  , 0.005517  , 0.005517  , 0.005517  , 0.005517  ,\n",
       "         0.00556426, 0.00556426, 0.00556426, 0.00556426, 0.00556426,\n",
       "         0.00551043, 0.00551043, 0.00551043, 0.00551043, 0.00551043,\n",
       "         0.00533719, 0.00533719, 0.00533719, 0.00533719, 0.00533719,\n",
       "         0.00403171, 0.00403171, 0.00403171, 0.00403171, 0.00403171,\n",
       "         0.00288584, 0.00288584, 0.00288584, 0.00288584, 0.00288584,\n",
       "         0.00525673, 0.00525673, 0.00525673, 0.00525673, 0.00525673,\n",
       "         0.00470009, 0.00470009, 0.00470009, 0.00470009, 0.00470009,\n",
       "         0.00425748, 0.00425748, 0.00425748, 0.00425748, 0.00425748,\n",
       "         0.00305486, 0.00305486, 0.00305486, 0.00305486, 0.00305486,\n",
       "         0.00244944, 0.00244944, 0.00244944, 0.00244944, 0.00244944,\n",
       "         0.00525673, 0.00525673, 0.00525673, 0.00525673, 0.00525673,\n",
       "         0.00454968, 0.00454968, 0.00454968, 0.00454968, 0.00454968,\n",
       "         0.0045503 , 0.0045503 , 0.0045503 , 0.0045503 , 0.0045503 ,\n",
       "         0.003417  , 0.003417  , 0.003417  , 0.003417  , 0.003417  ,\n",
       "         0.00255388, 0.00255388, 0.00255388, 0.00255388, 0.00255388,\n",
       "         0.00525673, 0.00525673, 0.00525673, 0.00525673, 0.00525673,\n",
       "         0.00454968, 0.00454968, 0.00454968, 0.00454968, 0.00454968,\n",
       "         0.0045503 , 0.0045503 , 0.0045503 , 0.0045503 , 0.0045503 ,\n",
       "         0.00343124, 0.00343124, 0.00343124, 0.00343124, 0.00343124,\n",
       "         0.00256258, 0.00256258, 0.00256258, 0.00256258, 0.00256258])},\n",
       " {'learning_rate': 0.05,\n",
       "  'max_depth': 15,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 48,\n",
       "  'reg_alpha': 0.05,\n",
       "  'reg_lambda': 0.0,\n",
       "  'subsample': 0.1},\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "         importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "         min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "         n_estimators=100, n_jobs=-1, num_leaves=48, objective=None,\n",
       "         random_state=None, reg_alpha=0.05, reg_lambda=0.0, silent=True,\n",
       "         subsample=0.1, subsample_for_bin=200000, subsample_freq=0))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {'learning_rate': 0.05,\n",
    "  'max_depth': 15,\n",
    "  'n_estimators': 100,\n",
    "  'num_leaves': 48,\n",
    "  'reg_alpha': 0.05,\n",
    "  'reg_lambda': 0.0,\n",
    "  'subsample': 0.1},\n",
    "\n",
    "grid_params = dict(n_estimators = [50,75,100, 150,200],\n",
    "                  subsample= [0.1,0.2,0.3,0.4,0.5],\n",
    "                   max_depth = [5,10,15,20,25])\n",
    "clazz = lgbm.LGBMClassifier\n",
    "detail, nest_param, best_lgbm = grid_train(clazz, best_params, grid_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.001, 0.02, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02083015, 0.00884614, 0.01865702, 0.00990977]),\n",
       " 'mean_score_time': array([0.00327182, 0.00207925, 0.00203381, 0.00151067]),\n",
       " 'mean_test_score': array([0.86934507, 0.85611224, 0.86873922, 0.86797817]),\n",
       " 'mean_train_score': array([0.92173275, 0.89340411, 0.92756923, 0.91425499]),\n",
       " 'param_C': masked_array(data=[0.01, 0.001, 0.02, 0.005],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.01}, {'C': 0.001}, {'C': 0.02}, {'C': 0.005}],\n",
       " 'rank_test_score': array([1, 4, 2, 3], dtype=int32),\n",
       " 'split0_test_score': array([0.84505929, 0.82134387, 0.84374177, 0.84453228]),\n",
       " 'split0_train_score': array([0.92263886, 0.89482006, 0.92812085, 0.91554649]),\n",
       " 'split1_test_score': array([0.82503294, 0.82747036, 0.82252964, 0.82608696]),\n",
       " 'split1_train_score': array([0.93183809, 0.90213355, 0.93718658, 0.92416164]),\n",
       " 'split2_test_score': array([0.88983957, 0.87513369, 0.89064171, 0.88756684]),\n",
       " 'split2_train_score': array([0.9217781 , 0.89272235, 0.92795504, 0.91432087]),\n",
       " 'split3_test_score': array([0.8802139 , 0.8657754 , 0.87807487, 0.88061497]),\n",
       " 'split3_train_score': array([0.91859402, 0.89110952, 0.92521158, 0.91121993]),\n",
       " 'split4_test_score': array([0.90717755, 0.89139234, 0.90933621, 0.90164598]),\n",
       " 'split4_train_score': array([0.9138147 , 0.88623507, 0.9193721 , 0.90602605]),\n",
       " 'std_fit_time': array([0.00693679, 0.00073186, 0.00534795, 0.00085575]),\n",
       " 'std_score_time': array([0.00209146, 0.00093258, 0.00075819, 0.00015267]),\n",
       " 'std_test_score': array([0.03008002, 0.02731041, 0.03154629, 0.02822627]),\n",
       " 'std_train_score': array([0.00592433, 0.00520256, 0.0057567 , 0.00594544])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.869345065786924"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_params = dict(max_iter=80, C= 0.01)\n",
    "model = LogisticRegression(**best_params)\n",
    "\n",
    "param = dict(C=[0.01, 0.001, 0.02, 0.005])\n",
    "\n",
    "clf = GridSearchCV(model, param, cv=5, n_jobs=1, verbose=1, scoring=\"roc_auc\")\n",
    "clf.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "# 打印参数的得分情况\n",
    "clf.cv_results_\n",
    "# 打印最佳参数\n",
    "clf.best_params_\n",
    "clf.best_score_\n",
    "best_lr = clf.best_estimator_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'min_samples_leaf': [1, 2, 3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.12622166, 0.10513282, 0.10966315, 0.11049008, 0.09939613]),\n",
       " 'mean_score_time': array([0.00973563, 0.00945997, 0.0097127 , 0.00999851, 0.00905838]),\n",
       " 'mean_test_score': array([0.86897652, 0.87158194, 0.8679634 , 0.86881835, 0.86486321]),\n",
       " 'mean_train_score': array([0.9269335 , 0.90976297, 0.90032629, 0.89670601, 0.89153403]),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 2, 3, 4, 5],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'min_samples_leaf': 1},\n",
       "  {'min_samples_leaf': 2},\n",
       "  {'min_samples_leaf': 3},\n",
       "  {'min_samples_leaf': 4},\n",
       "  {'min_samples_leaf': 5}],\n",
       " 'rank_test_score': array([2, 1, 4, 3, 5], dtype=int32),\n",
       " 'split0_test_score': array([0.85      , 0.85652174, 0.85461133, 0.85375494, 0.84018445]),\n",
       " 'split0_train_score': array([0.92888016, 0.91581767, 0.90283862, 0.90041052, 0.8982995 ]),\n",
       " 'split1_test_score': array([0.83017128, 0.83214756, 0.83234519, 0.83043478, 0.8326087 ]),\n",
       " 'split1_train_score': array([0.93789999, 0.91920115, 0.90930937, 0.90771567, 0.90056906]),\n",
       " 'split2_test_score': array([0.89959893, 0.89639037, 0.88890374, 0.89298128, 0.8861631 ]),\n",
       " 'split2_train_score': array([0.9239313 , 0.90173836, 0.89574431, 0.89330013, 0.88603412]),\n",
       " 'split3_test_score': array([0.86283422, 0.86557487, 0.8605615 , 0.87032086, 0.86356952]),\n",
       " 'split3_train_score': array([0.93009161, 0.90939511, 0.90033337, 0.89571937, 0.88996226]),\n",
       " 'split4_test_score': array([0.90279277, 0.90778467, 0.9038721 , 0.89705882, 0.90232056]),\n",
       " 'split4_train_score': array([0.91386447, 0.90266257, 0.89340577, 0.88638437, 0.88280524]),\n",
       " 'std_fit_time': array([0.02349557, 0.00194594, 0.00424843, 0.00903432, 0.00165856]),\n",
       " 'std_score_time': array([0.0012473 , 0.00035144, 0.00017327, 0.00091256, 0.00032191]),\n",
       " 'std_test_score': array([0.02822954, 0.02735874, 0.02540439, 0.02484125, 0.02647736]),\n",
       " 'std_train_score': array([0.00792262, 0.00693807, 0.00558383, 0.00712805, 0.0068748 ])}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8715819360838856"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_params = dict(n_estimators=80,min_samples_leaf=2,max_depth=7,oob_score=True)\n",
    "model = RandomForestClassifier(**best_params)\n",
    "\n",
    "param = dict(min_samples_leaf=[1,2,3,4,5])\n",
    "\n",
    "clf = GridSearchCV(model, param, cv=5, n_jobs=1, verbose=1, scoring=\"roc_auc\")\n",
    "clf.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "# 打印参数的得分情况\n",
    "clf.cv_results_\n",
    "# 打印最佳参数\n",
    "clf.best_params_\n",
    "clf.best_score_\n",
    "best_rf = clf.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=150,min_samples_leaf=3,max_depth=6,oob_score=True)\n",
    "rf.fit(train_data_X,train_data_Y)\n",
    "\n",
    "test_data[\"Survived\"] = rf.predict(test_data_X)\n",
    "RF = test_data[['PassengerId','Survived']].set_index('PassengerId')\n",
    "RF.to_csv('RF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    8.3s finished\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=350, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'C': [0.5, 1, 1.5]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.45916414, 0.46238079, 0.44962864]),\n",
       " 'mean_score_time': array([0.02009602, 0.02110949, 0.01882019]),\n",
       " 'mean_test_score': array([0.8382128 , 0.83616546, 0.83446574]),\n",
       " 'mean_train_score': array([0.9011646 , 0.9198269 , 0.92507828]),\n",
       " 'param_C': masked_array(data=[0.5, 1, 1.5],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.5}, {'C': 1}, {'C': 1.5}],\n",
       " 'rank_test_score': array([1, 2, 3], dtype=int32),\n",
       " 'split0_test_score': array([0.79789196, 0.80513834, 0.80948617]),\n",
       " 'split0_train_score': array([0.90741112, 0.9243911 , 0.92929735]),\n",
       " 'split1_test_score': array([0.81541502, 0.81607378, 0.81620553]),\n",
       " 'split1_train_score': array([0.90666433, 0.91674385, 0.9264312 ]),\n",
       " 'split2_test_score': array([0.85508021, 0.84705882, 0.85427807]),\n",
       " 'split2_train_score': array([0.90347173, 0.92063914, 0.92755599]),\n",
       " 'split3_test_score': array([0.83596257, 0.83034759, 0.82299465]),\n",
       " 'split3_train_score': array([0.90159287, 0.92580184, 0.93030777]),\n",
       " 'split4_test_score': array([0.88734485, 0.88275769, 0.86980572]),\n",
       " 'split4_train_score': array([0.88668298, 0.91155856, 0.9117991 ]),\n",
       " 'std_fit_time': array([0.01793443, 0.03177079, 0.04179893]),\n",
       " 'std_score_time': array([0.00075527, 0.0038275 , 0.00176064]),\n",
       " 'std_test_score': array([0.03111942, 0.02713319, 0.02334842]),\n",
       " 'std_train_score': array([0.00754307, 0.00519735, 0.00677428])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8382127976251005"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "best_params = dict(C=0.5,max_iter=350, probability=True)\n",
    "model = svm.SVC(**best_params)\n",
    "\n",
    "param = dict(C=[0.5,1,1.5])\n",
    "\n",
    "clf = GridSearchCV(model, param, cv=5, n_jobs=1, verbose=1, scoring=\"roc_auc\")\n",
    "clf.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "# 打印参数的得分情况\n",
    "clf.cv_results_\n",
    "# 打印最佳参数\n",
    "clf.best_params_\n",
    "clf.best_score_\n",
    "best_svm = clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voting_model(model_dict, x, y, voting= 'hard'):\n",
    "    vot_model = VotingClassifier(estimators=model_dict.items(),\n",
    "                           voting='soft')\n",
    "    vot_model.fit(x,y)\n",
    "    return vot_model\n",
    "    \n",
    "# model_dict.update(vot_hard = vot_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35353535353535354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.373737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.484067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   418.000000  891.000000\n",
       "mean   1100.500000    0.373737\n",
       "std     120.810458    0.484067\n",
       "min     892.000000    0.000000\n",
       "25%     996.250000    0.000000\n",
       "50%    1100.500000    0.000000\n",
       "75%    1204.750000    1.000000\n",
       "max    1309.000000    1.000000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.373737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.484067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived\n",
       "count  891.000000\n",
       "mean     0.373737\n",
       "std      0.484067\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, x, adjust=0.37320):    \n",
    "    arr = model.predict(x)\n",
    "    print(\"origin rate:\", sum(arr)/arr.shape[0])\n",
    "    if adjust:\n",
    "        tmp = model.predict_proba(x)[:,-1]\n",
    "        rank = int(tmp.shape[0] * adjust)\n",
    "        threshold = np.sort(tmp)[::-1][rank]\n",
    "        arr = np.array([1 if e>=threshold else 0 for e in tmp])\n",
    "    rs_df = pd.DataFrame(arr, columns=['Survived'], dtype=np.int)   \n",
    "    return rs_df\n",
    "\n",
    "\n",
    "df = predict(vot, train_data_X_sd)\n",
    "rs_df = get_result(test_data, df, label=  True)\n",
    "rs_df.describe()\n",
    "df.describe()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37320574162679426\n"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "from utils import  get_today_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_result(df, label_arr, label, record=False):\n",
    "    id_series = df['PassengerId'].astype(np.int)\n",
    "    label_series = label_arr\n",
    "    rs_df = pd.concat([id_series, label_series], axis=1)\n",
    "    if record:\n",
    "        path = 'submit/titanic/{label}-{day}.csv'.format(day=get_today_str(), label=label)\n",
    "        rs_df.to_csv(path,index=False)\n",
    "    return rs_df\n",
    "\n",
    "test_y_df = predict(best_model, test_data_X_sd)\n",
    "# test_y = np.ones(test_data_X.shape[0])\n",
    "\n",
    "# test_y\n",
    "# test_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21834427, 0.1958945 , 0.15457846, 0.07003827],\n",
       "       [0.93222684, 0.89787837, 0.91714896, 0.97558928],\n",
       "       [0.45517885, 0.47935707, 0.31742547, 0.37637343],\n",
       "       ...,\n",
       "       [0.5043876 , 0.46928658, 0.45154411, 0.29441349],\n",
       "       [0.43776052, 0.36467748, 0.20917513, 0.57883151],\n",
       "       [0.13221553, 0.11764616, 0.17126467, 0.01318203]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.118446  , 0.10776044, 0.15508261, 0.01205484],\n",
       "       [0.65619667, 0.54203836, 0.83882433, 0.42008801],\n",
       "       [0.22668474, 0.14184665, 0.15494618, 0.03299659],\n",
       "       ...,\n",
       "       [0.13857309, 0.14245641, 0.14519169, 0.02071692],\n",
       "       [0.08675219, 0.10816176, 0.16687677, 0.06045393],\n",
       "       [0.65652502, 0.55865447, 0.79386104, 0.84697805]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分train数据集,调用代码,把数据集名字转成和代码一样\n",
    "def staking_model(X, y, X_predict, clfs, n_folds-5):\n",
    "    \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "    secode_x = np.zeros((X.shape[0], len(clfs)))\n",
    "    secode_test_x = np.zeros((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "    for i, m in enumerate(clfs):    \n",
    "        pred_matrix = np.zeros((X_predict.shape[0], n_folds))\n",
    "\n",
    "        for j, (train_idx, test_idx) in enumerate(skf.split(X,y)):\n",
    "            tmp_x = X[train_idx]\n",
    "            tmp_y = y[train_idx]\n",
    "            pred_x = X[test_idx]\n",
    "            m = m.fit(tmp_x, tmp_y)\n",
    "            secode_x[test_idx, i] = m.predict_proba(pred_x)[:,1]\n",
    "            pred_matrix[:,j] = m.predict_proba(X_predict)[:,1]\n",
    "\n",
    "        secode_test_x[:,i] = pred_matrix.mean(axis=1)\n",
    "        clf2.fit(secode_x, y)\n",
    "        tmp = predict(clf2,secode_test_x)\n",
    "        return tmp\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3708133971291866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418, 1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "5            897         0\n",
       "6            898         1\n",
       "7            899         0\n",
       "8            900         1\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         1\n",
       "19           911         1\n",
       "20           912         0\n",
       "21           913         1\n",
       "22           914         1\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         0\n",
       "28           920         0\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         1\n",
       "392         1284         1\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         1\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         1\n",
       "409         1301         1\n",
       "410         1302         1\n",
       "411         1303         1\n",
       "412         1304         1\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,max_iter=100)\n",
    "clf2.fit(secode_x, train_data_Y)\n",
    "tmp = predict(clf2,secode_test_x)\n",
    "tmp.shape\n",
    "\n",
    "get_result(test_data, tmp, label='stacking', record=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 195)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function:roc-auc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-eba2f195e234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mk_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roc-auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m k_model.fit(train_data_X_sd, train_data_Y, validation_split=0.1, epochs=50, batch_size=32,\n\u001b[1;32m     16\u001b[0m             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    902\u001b[0m                             \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                             \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m                             \u001b[0mweighted_metric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_weighted_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                             \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                                     printable_module_name='metric function')\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 163\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown metric function:roc-auc"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras import regularizers\n",
    "\n",
    "train_data_X_sd.shape\n",
    "train_data_Y.reshape((-1,1)).shape\n",
    "\n",
    "\n",
    "k_model = Sequential()\n",
    "k_model.add(Dense(units=256, input_dim = train_data_X_sd.shape[1], activation=\"relu\"))\n",
    "k_model.add(Dense(units=128,activation=\"relu\"))\n",
    "k_model.add(Dense(units=64,activation=\"relu\"))\n",
    "k_model.add(Dense(units=64,activation=\"relu\"))\n",
    "k_model.add(Dense(units=1,activation=\"sigmoid\",activity_regularizer=regularizers.l2(0.02)))\n",
    "\n",
    "\n",
    "\n",
    "k_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "k_model.fit(train_data_X_sd, train_data_Y, validation_split=0.1, epochs=50, batch_size=32,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=0,\n",
    "                              verbose=1, mode='auto')])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# k_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47081625]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         1\n",
       "4            896         1\n",
       "5            897         1\n",
       "6            898         0\n",
       "7            899         1\n",
       "8            900         1\n",
       "9            901         1\n",
       "10           902         0\n",
       "11           903         1\n",
       "12           904         0\n",
       "13           905         0\n",
       "14           906         0\n",
       "15           907         0\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         1\n",
       "19           911         1\n",
       "20           912         1\n",
       "21           913         0\n",
       "22           914         0\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         1\n",
       "28           920         1\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         0\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         0\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         1\n",
       "399         1291         1\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         0\n",
       "403         1295         1\n",
       "404         1296         1\n",
       "405         1297         1\n",
       "406         1298         1\n",
       "407         1299         1\n",
       "408         1300         0\n",
       "409         1301         0\n",
       "410         1302         0\n",
       "411         1303         0\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         0\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = predict(k_model, test_data_X_sd)\n",
    "get_result(test_data, tmp, 'keras', True)\n",
    "\n",
    "# k_model.predict_proba(train_data_X_sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lml-py",
   "language": "python",
   "name": "lml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
