{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Survived    Pclass       Age     SibSp     Parch      Fare\n",
       "Survived  1.000000 -0.338481 -0.077221 -0.035322  0.081629  0.257307\n",
       "Pclass   -0.338481  1.000000 -0.369226  0.083081  0.018443 -0.549500\n",
       "Age      -0.077221 -0.369226  1.000000 -0.308247 -0.189119  0.096067\n",
       "SibSp    -0.035322  0.083081 -0.308247  1.000000  0.414838  0.159651\n",
       "Parch     0.081629  0.018443 -0.189119  0.414838  1.000000  0.216225\n",
       "Fare      0.257307 -0.549500  0.096067  0.159651  0.216225  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd3996ccc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd3996ccc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd2d9d1080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fbd35580860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fbd2d8bd780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd2d783710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data.describe()\n",
    "train_data.head()\n",
    "train_data.info()\n",
    "test_data.info()\n",
    "\n",
    "train_corr = train_data.drop('PassengerId', axis=1).corr()\n",
    "train_corr\n",
    "a = plt.subplots(figsize = (15,9))\n",
    "sns.heatmap(train_corr,vmin=-1, vmax=1,annot=True, square=True)\n",
    "\n",
    "\n",
    "train_data.groupby(\"Pclass\")['Survived'].mean().plot.bar()\n",
    "\n",
    "train_data.groupby(['Sex'])['Sex','Survived'].mean().plot.bar()\n",
    "\n",
    "g = sns.FacetGrid(train_data, col='Survived',size=5)\n",
    "g.map(plt.hist, 'Age', bins=40)\n",
    "\n",
    "g = sns.FacetGrid(train_data, col='Survived',size=5)\n",
    "g.map(plt.hist, 'Fare', bins=40)\n",
    "sns.countplot(\"Embarked\", hue = 'Survived', data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_parse(df):\n",
    "    df['SibSp_Parch'] = df['SibSp'] + df['Parch']\n",
    "    df.Embarked.fillna(df.Embarked.mode()[0], inplace=True)\n",
    "\n",
    "    df[\"Fare\"].fillna(14.435422,inplace=True)\n",
    "\n",
    "    df['Name1'] = df['Name'].str.extract('.+,(.+)', expand=False).str.extract('^(.+?)\\.', expand=False).str.strip()\n",
    "\n",
    "    df['Name1'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer' , inplace = True)\n",
    "    df['Name1'].replace(['Jonkheer', 'Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty' , inplace = True)\n",
    "    df['Name1'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs', inplace = True)\n",
    "    df['Name1'].replace(['Mlle', 'Miss'], 'Miss', inplace = True)\n",
    "    df['Name1'].replace(['Mr'], 'Mr' , inplace = True)\n",
    "    df['Name1'].replace(['Master'], 'Master' , inplace = True)\n",
    "    df = pd.get_dummies(df,columns=['Pclass','Sex','SibSp','Parch','SibSp_Parch', \"Embarked\", 'Name1'])\n",
    "\n",
    "    df['Name2'] = df['Name'].apply(lambda x: x.split('.')[1])\n",
    "    Name2_sum = df['Name2'].value_counts().reset_index()\n",
    "    Name2_sum.columns=['Name2','Name2_sum']\n",
    "    df = pd.merge(df,Name2_sum,how='left',on='Name2')\n",
    "\n",
    "    #由于出现一次时该特征时无效特征,用one来代替出现一次的姓\n",
    "    df.loc[df['Name2_sum'] == 1 , 'Name2_new'] = 'one'\n",
    "    df.loc[df['Name2_sum'] > 1 , 'Name2_new'] = df['Name2']\n",
    "    del df['Name2']\n",
    "    df = pd.get_dummies(df,columns=['Name2_new'])\n",
    "    del df['Name']\n",
    "\n",
    "\n",
    "\n",
    "    df['Ticket_Letter'] = df['Ticket'].str.split().str[0]\n",
    "    df['Ticket_Letter'] = df['Ticket_Letter'].apply(lambda x:np.nan if x.isnumeric() else x)\n",
    "    df.drop('Ticket',inplace=True,axis=1)\n",
    "    df = pd.get_dummies(df,columns=['Ticket_Letter'],drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df.loc[df[\"Age\"].isnull() ,\"age_nan\"] = 1\n",
    "    df.loc[df[\"Age\"].notnull() ,\"age_nan\"] = 0\n",
    "    df = pd.get_dummies(df,columns=['age_nan'])\n",
    "\n",
    "    missing_age = df.drop(['Survived','Cabin'],axis=1)\n",
    "\n",
    "    #分列处理\n",
    "\n",
    "\n",
    "    #将Age完整的项作为训练集、将Age缺失的项作为测试集。\n",
    "    missing_age_train = missing_age[missing_age['Age'].notnull()]\n",
    "    missing_age_test = missing_age[missing_age['Age'].isnull()]\n",
    "    missing_age_X_train = missing_age_train.drop(['Age'], axis=1)\n",
    "    missing_age_Y_train = missing_age_train['Age']\n",
    "    missing_age_X_test = missing_age_test.drop(['Age'], axis=1)\n",
    "\n",
    "    # 先将数据标准化\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    #用测试集训练并标准化\n",
    "\n",
    "\n",
    "    ss.fit(missing_age_X_train)\n",
    "    missing_age_X_train = ss.transform(missing_age_X_train)\n",
    "    missing_age_X_test = ss.transform(missing_age_X_test)\n",
    "    lin = linear_model.BayesianRidge()\n",
    "    lin.fit(missing_age_X_train,missing_age_Y_train)\n",
    "    df.loc[(df['Age'].isnull()), 'Age'] = lin.predict(missing_age_X_test)\n",
    "\n",
    "    df['Age'] = pd.cut(df['Age'], bins=[0,10,18,30,50,100],labels=[1,2,3,4,5])\n",
    "    df = pd.get_dummies(df,columns=['Age'])\n",
    "\n",
    "\n",
    "    df['Cabin_nan'] = df['Cabin'].apply(lambda x:str(x)[0] if pd.notnull(x) else x)\n",
    "    df = pd.get_dummies(df,columns=['Cabin_nan'])\n",
    "    df.loc[df[\"Cabin\"].isnull() ,\"Cabin_nan\"] = 1\n",
    "    df.loc[df[\"Cabin\"].notnull() ,\"Cabin_nan\"] = 0\n",
    "    df = pd.get_dummies(df,columns=['Cabin_nan'])\n",
    "    df.drop(['Cabin', 'PassengerId'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/ipykernel_launcher.py:62: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/ipykernel_launcher.py:63: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 132.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_nan_A</th>\n",
       "      <th>Cabin_nan_B</th>\n",
       "      <th>Cabin_nan_C</th>\n",
       "      <th>Cabin_nan_D</th>\n",
       "      <th>Cabin_nan_E</th>\n",
       "      <th>Cabin_nan_F</th>\n",
       "      <th>Cabin_nan_G</th>\n",
       "      <th>Cabin_nan_T</th>\n",
       "      <th>Cabin_nan_0.0</th>\n",
       "      <th>Cabin_nan_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  SibSp_0  \\\n",
       "0   7.2500         0         0         1           0         1        0   \n",
       "1  71.2833         1         0         0           1         0        0   \n",
       "2   7.9250         0         0         1           1         0        1   \n",
       "3  53.1000         1         0         0           1         0        0   \n",
       "4   8.0500         0         0         1           0         1        1   \n",
       "\n",
       "   SibSp_1  SibSp_2  SibSp_3      ...        Cabin_nan_A  Cabin_nan_B  \\\n",
       "0        1        0        0      ...                  0            0   \n",
       "1        1        0        0      ...                  0            0   \n",
       "2        0        0        0      ...                  0            0   \n",
       "3        1        0        0      ...                  0            0   \n",
       "4        0        0        0      ...                  0            0   \n",
       "\n",
       "   Cabin_nan_C  Cabin_nan_D  Cabin_nan_E  Cabin_nan_F  Cabin_nan_G  \\\n",
       "0            0            0            0            0            0   \n",
       "1            1            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            1            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Cabin_nan_T  Cabin_nan_0.0  Cabin_nan_1.0  \n",
       "0            0              0              1  \n",
       "1            0              1              0  \n",
       "2            0              0              1  \n",
       "3            0              1              0  \n",
       "4            0              0              1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Columns: 195 entries, Fare to Cabin_nan_1.0\n",
      "dtypes: float64(1), int64(1), uint8(193)\n",
      "memory usage: 188.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/ipykernel_launcher.py:22: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.50244517, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       [ 0.78684529,  1.76776695, -0.51015154, ..., -0.03352008,\n",
       "         1.835115  , -1.835115  ],\n",
       "       [-0.48885426, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       ...,\n",
       "       [-0.17626324, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498],\n",
       "       [-0.04438104,  1.76776695, -0.51015154, ..., -0.03352008,\n",
       "         1.835115  , -1.835115  ],\n",
       "       [-0.49237783, -0.56568542, -0.51015154, ..., -0.03352008,\n",
       "        -0.54492498,  0.54492498]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(df, train_num):\n",
    "    train_data = df[:train_num]\n",
    "    test_data = df[train_num:]\n",
    "    train_data_X = train_data.drop(['Survived'],axis=1)\n",
    "    train_data_Y = train_data['Survived']\n",
    "    test_data_X = test_data.drop(['Survived'],axis=1)\n",
    "    return train_data_X, train_data_Y, test_data_X\n",
    "\n",
    "test_data['Survived'] = 0\n",
    "train_test = train_data.append(test_data)\n",
    "train_test.info()\n",
    "parsed_data = feature_parse(train_test)\n",
    "\n",
    "\n",
    "train_data_X, train_data_Y, test_data_X = split_data(parsed_data, train_data.shape[0])\n",
    "train_data_X.head()\n",
    "train_data_X.info()\n",
    "\n",
    "ss2 = StandardScaler()\n",
    "ss2.fit(train_data_X)\n",
    "train_data_X_sd = ss2.transform(train_data_X)\n",
    "test_data_X_sd = ss2.transform(test_data_X)\n",
    "train_data_X_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_nan_A</th>\n",
       "      <th>Cabin_nan_B</th>\n",
       "      <th>Cabin_nan_C</th>\n",
       "      <th>Cabin_nan_D</th>\n",
       "      <th>Cabin_nan_E</th>\n",
       "      <th>Cabin_nan_F</th>\n",
       "      <th>Cabin_nan_G</th>\n",
       "      <th>Cabin_nan_T</th>\n",
       "      <th>Cabin_nan_0.0</th>\n",
       "      <th>Cabin_nan_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  SibSp_0  \\\n",
       "0   7.2500         0         0         1           0         1        0   \n",
       "1  71.2833         1         0         0           1         0        0   \n",
       "2   7.9250         0         0         1           1         0        1   \n",
       "3  53.1000         1         0         0           1         0        0   \n",
       "4   8.0500         0         0         1           0         1        1   \n",
       "\n",
       "   SibSp_1  SibSp_2  SibSp_3      ...        Cabin_nan_A  Cabin_nan_B  \\\n",
       "0        1        0        0      ...                  0            0   \n",
       "1        1        0        0      ...                  0            0   \n",
       "2        0        0        0      ...                  0            0   \n",
       "3        1        0        0      ...                  0            0   \n",
       "4        0        0        0      ...                  0            0   \n",
       "\n",
       "   Cabin_nan_C  Cabin_nan_D  Cabin_nan_E  Cabin_nan_F  Cabin_nan_G  \\\n",
       "0            0            0            0            0            0   \n",
       "1            1            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            1            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Cabin_nan_T  Cabin_nan_0.0  Cabin_nan_1.0  \n",
       "0            0              0              1  \n",
       "1            0              1              0  \n",
       "2            0              0              1  \n",
       "3            0              1              0  \n",
       "4            0              0              1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Columns: 195 entries, Fare to Cabin_nan_1.0\n",
      "dtypes: float64(1), int64(1), uint8(193)\n",
      "memory usage: 188.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_data_X.head()\n",
    "train_data_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_result(model, x, y):\n",
    "    pred = model.predict(x)\n",
    "    acc = accuracy_score(pred, y)\n",
    "    auc = roc_auc_score(pred, y)\n",
    "    \n",
    "    return dict(acc=acc,auc=auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_train(clazz, best_params, grid_params, n_fold=5, scoring= 'roc_auc'):\n",
    "    model = clazz(**best_params)\n",
    "    clf = GridSearchCV(model, grid_params, cv=n_fold, n_jobs=4, verbose=1, scoring=scoring)\n",
    "    clf.fit(train_data_X_sd, train_data_Y)\n",
    "    detail = clf.cv_results_\n",
    "    best_params.update(clf.best_params_)\n",
    "    best_model = clazz(**best_params)\n",
    "    return detail, best_params, best_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x, adjust=0.37320):    \n",
    "    arr = model.predict(x)\n",
    "    print(\"origin rate:\", sum(arr)/arr.shape[0])\n",
    "    if adjust:\n",
    "        tmp = model.predict_proba(x)[:,-1]\n",
    "        rank = int(tmp.shape[0] * adjust)\n",
    "        threshold = np.sort(tmp)[::-1][rank]\n",
    "        arr = np.array([1 if e>=threshold else 0 for e in tmp])\n",
    "    rs_df = pd.DataFrame(arr, columns=['Survived'], dtype=np.int)   \n",
    "    return rs_df\n",
    "\n",
    "from utils import  get_today_str\n",
    "import sys, os\n",
    "COMP_NAME = 'titanic'\n",
    "\n",
    "def get_result(df, label_arr, label, record=False, submit=False, message=''):\n",
    "    id_series = df['PassengerId'].astype(np.int)\n",
    "    label_series = label_arr\n",
    "    rs_df = pd.concat([id_series, label_series], axis=1)\n",
    "    if record:\n",
    "        path = 'submit/titanic/{label}-{day}.csv'.format(day=get_today_str(), label=label)\n",
    "        rs_df.to_csv(path,index=False)\n",
    "        if submit:\n",
    "            do_submit(COMP_NAME, path, message)\n",
    "    return rs_df\n",
    "\n",
    "def do_execute(cmd):\n",
    "    print(\"executing cmd:{}\".format(cmd))\n",
    "    return os.system(cmd)\n",
    "\n",
    "def do_submit(comp_name, path, message):\n",
    "    cmd = 'kaggle competitions submit -c {comp_name} -f {path} -m \"{message}\"'.format(comp_name=comp_name, path=path, message=message)\n",
    "    return do_execute(cmd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "        importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "        random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "        subsample=0.01, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "        importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "        random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "        subsample=0.01, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'best_lgbm': (LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "          importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "          min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "          n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "          random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "          subsample=0.01, subsample_for_bin=200000, subsample_freq=0),\n",
       "  0.8797477224399548)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {'n_estimators': 115,\n",
    " 'max_depth': 15,\n",
    " 'learning_rate': 0.05,\n",
    " 'subsample': 0.01,\n",
    " 'reg_alpha': 0.05,\n",
    " 'reg_lambda': 0.05,\n",
    " 'num_leaves': 48,\n",
    " 'colsample_bytree': 0.5}\n",
    "\n",
    "\n",
    "grid_params = dict(\n",
    "                   subsample= [0.01,0.02,0.05,0.1,0.15],\n",
    "                   reg_lambda= [0.0, 0.01,0.05, 0.1,0.2],\n",
    "                   colsample_bytree = [0.1, 0.2,0.5,1.]\n",
    ")\n",
    "clazz = lgbm.LGBMClassifier\n",
    "detail, nest_param, best_lgbm = grid_train(clazz, best_params, grid_params)\n",
    "best_lgbm.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "best_lgbm\n",
    "test_score = max(detail[\"mean_test_score\"])\n",
    "best_clf_dict[\"best_lgbm\"] = (best_lgbm, test_score)\n",
    "best_clf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'best_lgbm': (LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "          importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "          min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "          n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "          random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "          subsample=0.01, subsample_for_bin=200000, subsample_freq=0),\n",
       "  0.8797477224399548),\n",
       " 'best_lr': (LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False), 0.8693451853877824)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_params = dict(max_iter=80, C= 0.01)\n",
    "\n",
    "grid_params = dict(C=[0.01, 0.001, 0.02, 0.005])\n",
    "\n",
    "clazz = LogisticRegression\n",
    "\n",
    "detail, nest_param, best_lr = grid_train(clazz, best_params, grid_params)\n",
    "best_lr.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "best_lr\n",
    "test_score  = max(detail[\"mean_test_score\"])\n",
    "best_clf_dict[\"best_lr\"] = (best_lr, test_score)\n",
    "best_clf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  18 out of  25 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'best_lgbm': (LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "          importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "          min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "          n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "          random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "          subsample=0.01, subsample_for_bin=200000, subsample_freq=0),\n",
       "  0.8797477224399548),\n",
       " 'best_lr': (LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False), 0.8693451853877824),\n",
       " 'best_rf': (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "              oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "  0.8711893768196133)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_params = dict(n_estimators=80,min_samples_leaf=2,max_depth=7,oob_score=True)\n",
    "grid_params = dict(min_samples_leaf=[1,2,3,4,5])\n",
    "\n",
    "\n",
    "clazz = RandomForestClassifier\n",
    "\n",
    "detail, nest_param, best_rf = grid_train(clazz, best_params, grid_params)\n",
    "best_rf.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "test_score  = max(detail[\"mean_test_score\"])\n",
    "best_clf_dict[\"best_rf\"] = (best_rf, test_score)\n",
    "best_clf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    1.7s finished\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=350, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'best_lgbm': (LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "          importance_type='split', learning_rate=0.05, max_depth=15,\n",
       "          min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "          n_estimators=115, n_jobs=-1, num_leaves=48, objective=None,\n",
       "          random_state=None, reg_alpha=0.05, reg_lambda=0.05, silent=True,\n",
       "          subsample=0.01, subsample_for_bin=200000, subsample_freq=0),\n",
       "  0.8797477224399548),\n",
       " 'best_lr': (LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=80, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False), 0.8693451853877824),\n",
       " 'best_rf': (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "              oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "  0.8711893768196133),\n",
       " 'best_svc': (SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=350, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False), 0.8382127976251005)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "best_params = dict(C=0.5,max_iter=350, probability=True)\n",
    "grid_params = dict(C=[0.5,1,1.5])\n",
    "\n",
    "clazz = SVC\n",
    "\n",
    "detail, nest_param, best_svc = grid_train(clazz, best_params, grid_params)\n",
    "best_svc.fit(train_data_X_sd, train_data_Y)\n",
    "\n",
    "test_score  = max(detail[\"mean_test_score\"])\n",
    "best_clf_dict[\"best_svc\"] = (best_svc, test_score)\n",
    "best_clf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=350).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/xiaowa/.virtualenvs/py3.6-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.StackingModel at 0x7fbd31d7fc18>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06272351, 0.17422427, 0.14161532, 0.15383874],\n",
       "       [0.96068218, 0.91624658, 0.91925622, 0.88109965],\n",
       "       [0.50411192, 0.60330097, 0.53913274, 0.55844144],\n",
       "       ...,\n",
       "       [0.20892599, 0.4384676 , 0.41655687, 0.34489578],\n",
       "       [0.63402394, 0.49312461, 0.39994219, 0.25006994],\n",
       "       [0.01583228, 0.11311615, 0.1009569 , 0.15537008]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.82863318, 0.17136682],\n",
       "       [0.14702929, 0.85297071],\n",
       "       [0.45930168, 0.54069832],\n",
       "       ...,\n",
       "       [0.67445193, 0.32554807],\n",
       "       [0.51456902, 0.48543098],\n",
       "       [0.85070192, 0.14929808]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "class StackingModel:\n",
    "    def __init__(self, clf_list, clf2, n_folds):\n",
    "        self.clf_list  = clf_list\n",
    "        self.clf_instance_list = []\n",
    "        \n",
    "        self.clf2 = clf2\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        skf = StratifiedKFold(n_splits=self.n_folds)\n",
    "        skf.get_n_splits(X, y)\n",
    "        self.clf_instance_list = []\n",
    "        self.second_x = np.zeros((X.shape[0], len(clf_list)))\n",
    "        for i, m in enumerate(self.clf_list):   \n",
    "            instance_list = []\n",
    "            for j, (train_idx, test_idx) in enumerate(skf.split(X,y)):\n",
    "                tmp_x = X[train_idx]\n",
    "                tmp_y = y[train_idx]\n",
    "                tmp_m = copy.copy(m)\n",
    "                tmp_m = tmp_m.fit(tmp_x, tmp_y)\n",
    "                tmp_pred_x = X[test_idx]\n",
    "                \n",
    "                self.second_x[test_idx, i] = tmp_m.predict_proba(tmp_pred_x)[:,-1]\n",
    "                instance_list.append(tmp_m)\n",
    "                \n",
    "            self.clf_instance_list.append(instance_list)\n",
    "\n",
    "        self.clf2.fit(self.second_x, y)\n",
    "        return self\n",
    "    \n",
    "    def parse_predict_x(self, X):\n",
    "        second_x = np.zeros((X.shape[0], len(self.clf_list)))\n",
    "        for idx, instance_list in enumerate(self.clf_instance_list):\n",
    "            tmp_x = np.zeros((X.shape[0], len(instance_list)))\n",
    "            for j, instance in enumerate(instance_list):\n",
    "                tmp_x[:,j] = instance.predict_proba(X)[:,-1]\n",
    "            tmp = np.mean(tmp_x, axis=1)\n",
    "            second_x[:,idx] = tmp\n",
    "        return second_x\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        second_x = self.parse_predict_x(X)\n",
    "        return self.clf2.predict_proba(second_x)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        second_x = self.parse_predict_x(X)\n",
    "        return self.clf2.predict(second_x)\n",
    "        \n",
    "                  \n",
    "            \n",
    "clf_list = [e[0] for e in best_clf_dict.values()]\n",
    "clf2 = LogisticRegression(C=0.1,max_iter=100)\n",
    "stacking_model = StackingModel(clf_list,clf2, 5)\n",
    "stacking_model.fit(train_data_X_sd, train_data_Y)\n",
    "# stacking_model.clf_instance_list\n",
    "\n",
    "# stacking_model.second_x\n",
    "# \n",
    "\n",
    "# stacking_model.parse_predict_x(train_data_X_sd)\n",
    "\n",
    "# stacking_model.predict(train_data_X_sd)\n",
    "# stacking_model.predict_proba(train_data_X_sd)\n",
    "\n",
    "\n",
    "# eval_result(stacking_model, train_data_X_sd, train_data_Y)\n",
    "\n",
    "\n",
    "# stacking_model.predict_proba(test_data_X_sd)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8731762065095399, 'auc': 0.8704948394684487}\n",
      "origin rate: 0.36363636363636365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.373206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.484236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   418.000000  418.000000\n",
       "mean   1100.500000    0.373206\n",
       "std     120.810458    0.484236\n",
       "min     892.000000    0.000000\n",
       "25%     996.250000    0.000000\n",
       "50%    1100.500000    0.000000\n",
       "75%    1204.750000    1.000000\n",
       "max    1309.000000    1.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_in_one(model, label, record, submit):\n",
    "    print(eval_result(model, train_data_X_sd, train_data_Y))\n",
    "    pred = predict(model, test_data_X_sd)\n",
    "    rs = get_result(test_data, pred, label, record, submit)\n",
    "    return rs\n",
    "    \n",
    "rs = all_in_one(stacking_model, 'stack', True, False)\n",
    "rs.describe()\n",
    "\n",
    "\n",
    "# eval_result(stacking_model, train_data_X_sd, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 195)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerry/py-envs/lml-py/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function:roc-auc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-eba2f195e234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mk_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roc-auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m k_model.fit(train_data_X_sd, train_data_Y, validation_split=0.1, epochs=50, batch_size=32,\n\u001b[1;32m     16\u001b[0m             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m                         \u001b[0mappend_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    902\u001b[0m                             \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                             \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m                             \u001b[0mweighted_metric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_weighted_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                             \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                                     printable_module_name='metric function')\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py-envs/lml-py/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 163\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown metric function:roc-auc"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras import regularizers\n",
    "\n",
    "train_data_X_sd.shape\n",
    "train_data_Y.reshape((-1,1)).shape\n",
    "\n",
    "\n",
    "k_model = Sequential()\n",
    "k_model.add(Dense(units=256, input_dim = train_data_X_sd.shape[1], activation=\"relu\"))\n",
    "k_model.add(Dense(units=128,activation=\"relu\"))\n",
    "k_model.add(Dense(units=64,activation=\"relu\"))\n",
    "k_model.add(Dense(units=64,activation=\"relu\"))\n",
    "k_model.add(Dense(units=1,activation=\"sigmoid\",activity_regularizer=regularizers.l2(0.02)))\n",
    "\n",
    "\n",
    "\n",
    "k_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "k_model.fit(train_data_X_sd, train_data_Y, validation_split=0.1, epochs=50, batch_size=32,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=0,\n",
    "                              verbose=1, mode='auto')])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# k_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47081625]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         1\n",
       "4            896         1\n",
       "5            897         1\n",
       "6            898         0\n",
       "7            899         1\n",
       "8            900         1\n",
       "9            901         1\n",
       "10           902         0\n",
       "11           903         1\n",
       "12           904         0\n",
       "13           905         0\n",
       "14           906         0\n",
       "15           907         0\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         1\n",
       "19           911         1\n",
       "20           912         1\n",
       "21           913         0\n",
       "22           914         0\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         1\n",
       "28           920         1\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         0\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         0\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         1\n",
       "399         1291         1\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         0\n",
       "403         1295         1\n",
       "404         1296         1\n",
       "405         1297         1\n",
       "406         1298         1\n",
       "407         1299         1\n",
       "408         1300         0\n",
       "409         1301         0\n",
       "410         1302         0\n",
       "411         1303         0\n",
       "412         1304         0\n",
       "413         1305         0\n",
       "414         1306         0\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = predict(k_model, test_data_X_sd)\n",
    "get_result(test_data, tmp, 'keras', True)\n",
    "\n",
    "# k_model.predict_proba(train_data_X_sd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6-env",
   "language": "python",
   "name": "py3.6-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
